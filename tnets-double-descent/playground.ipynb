{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82c61e55",
   "metadata": {},
   "source": [
    "# Imports and settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "516a8cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: JAX_ENABLE_X64=1\n",
      "env: JAX_PLATFORM_NAME=cpu\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%env JAX_ENABLE_X64=1\n",
    "%env JAX_PLATFORM_NAME=cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80210565",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import jit, grad\n",
    "from jax.example_libraries import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "933bc00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import time\n",
    "import itertools\n",
    "\n",
    "from collections import defaultdict\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b833c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, List, DefaultDict, Dict, Tuple, Optional"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc61c86",
   "metadata": {},
   "source": [
    "## Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a90da14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# type alias\n",
    "PRNGKeyArray = Any\n",
    "DeviceArray = jnp.DeviceArray"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83f3f8e",
   "metadata": {},
   "source": [
    "# Random Data Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c26e10",
   "metadata": {},
   "source": [
    "## MPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "1e7db4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "class MPS:\n",
    "\n",
    "    \"\"\"MPS class\"\"\"\n",
    "    \n",
    "    def __init__(self, size: int, local_dim: int, bond_dim: int):\n",
    "        self.size = size\n",
    "        self.local_dim = local_dim\n",
    "        self.bond_dim = bond_dim\n",
    "        self.svs = [None]*size\n",
    "        self.dw = [None]*size\n",
    "        self._tensors = [None]*size\n",
    "        self._normalized = False\n",
    "        self._normalization_method = None\n",
    "        self._norm = None\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f'An MPS of size: {self.size}; ' +\\\n",
    "               f'local dim: {self.local_dim}; ' +\\\n",
    "               f'bond dim: {self.bond_dim}.'\n",
    "\n",
    "    def __setitem__(self,idx, tensor):\n",
    "        self._tensors[idx] = tensor\n",
    "\n",
    "    def __getitem__(self, idx) -> DeviceArray:\n",
    "        return self._tensors[idx]\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.size\n",
    "\n",
    "    def __iter__(self):\n",
    "        pass\n",
    "\n",
    "    @property\n",
    "    def norm(self) -> jnp.double:\n",
    "        if self._norm is None:\n",
    "            self._norm = self.get_overlap(self.conjugate)\n",
    "        return jnp.real(self._norm)\n",
    "\n",
    "    @property\n",
    "    def conjugate(self):\n",
    "        self_conj = deepcopy(self)\n",
    "        self_conj._tensors = jax.tree_map(jnp.conj, self._tensors)\n",
    "        return self_conj\n",
    "\n",
    "    @property\n",
    "    def is_normalized(self) -> bool:\n",
    "        return self._normalized\n",
    "\n",
    "    @property\n",
    "    def normalization_method(self) -> str:\n",
    "        return self._normalization_method\n",
    "\n",
    "    def get_overlap(self, other) -> jnp.double:\n",
    "        \"\"\"\n",
    "        Overlap of this MPS with another MPS.\n",
    "        --A1----A2--...--An-- (this)\n",
    "          |     |        |\n",
    "        \n",
    "          |     |        |\n",
    "        --B1----B2--...--Bn-- (other)\n",
    "        \"\"\"\n",
    "        # contracts individual components\n",
    "        dot = lambda x, y: jnp.einsum('pqr,uqv->purv', x, y)\n",
    "        # multiply two neighbouring tensors\n",
    "        mult = lambda x, y: jnp.einsum('purv,rvts->puts', x, y)\n",
    "        # contract all\n",
    "        res = reduce(mult, jax.tree_multimap(dot, self._tensors, other._tensors))\n",
    "        return res.squeeze()\n",
    "\n",
    "    def check_normalization(self, method: str, idx=-1, tol=1e-5):\n",
    "\n",
    "        def _check(start, stop, method):\n",
    "            bad_sites = {}  # keep track where normalization fails\n",
    "            for i in range(start, stop, 1):\n",
    "                A = self[i]\n",
    "                u, _, w = A.shape\n",
    "                if method == 'left':\n",
    "                    A = A.reshape(-1, w)\n",
    "                elif method == \"right\":\n",
    "                    A = A.reshape(u, -1)\n",
    "                    A = A.conj().T\n",
    "                delta = jnp.max(abs(A.conj().T @ A - jnp.eye(A.shape[1])))\n",
    "                if  delta > tol:\n",
    "                    bad_sites[i] = delta\n",
    "            if bad_sites:\n",
    "                for i, delta in bad_sites.items():\n",
    "                    print(f'Badly normalized {i}-th site; delta: {delta}')\n",
    "            else:\n",
    "                print(f'The MPS is {method} normalized correctly between {start} and {stop-1}')\n",
    "\n",
    "        if method == 'left':\n",
    "            if idx == -1:\n",
    "                stop = self.size\n",
    "            else:\n",
    "                stop = idx\n",
    "            _check(0, stop, 'left')\n",
    "        elif method == 'right':\n",
    "            if idx == -1:\n",
    "                start = 0\n",
    "            else:\n",
    "                start = idx\n",
    "            _check(start, self.size, 'right')\n",
    "        elif method == 'site':\n",
    "            if not 0 < idx < self.size - 1:\n",
    "                raise ValueError('Need to provide site idx')\n",
    "            _check(0, idx, 'left')\n",
    "            _check(idx+1, self.size, 'right')\n",
    "        elif method == 'bond':\n",
    "            if not 0 < idx < self.size - 1:\n",
    "                raise ValueError('Need to provide site idx')\n",
    "            _check(0, idx+1, 'left')\n",
    "            _check(idx+1, self.size, 'right')\n",
    "        else:\n",
    "            raise ValueError(f'Unknown method {method}')\n",
    "\n",
    "    def normalize(self, method, idx=-1, max_bond=jnp.inf, force=False):\n",
    "        \"\"\"\n",
    "        Normalize to one of the canonical forms.\n",
    "\n",
    "        Input:\n",
    "        ------\n",
    "        method: str         One of the canonical forms, incl.\n",
    "                            'left', 'right', 'site' or 'bond'.\n",
    "        idx: int            A site index which is used to stop\n",
    "                            the normalization process. The value of -1\n",
    "                            indicates a full propagations. Default: -1.\n",
    "        max_bond: int       Max bond dimension to keep Default: np.inf.\n",
    "        force: bool         Force normalizaion even if already normalized.\n",
    "        \"\"\"\n",
    "        if self.is_normalized and not force:\n",
    "            print('The MPS is already normalized using' +\\\n",
    "                  f' the \"{self.normalization_method}\" method.' +\\\n",
    "                  f' Use force=True to renormalize')\n",
    "            return\n",
    "\n",
    "        {\n",
    "            'left': self._left_normalize,\n",
    "            'right': self._right_normalize,\n",
    "            'bond': self._bond_normalize,\n",
    "            'site': self._site_normalize\n",
    "        }[method](idx, max_bond)\n",
    "\n",
    "        self._normalized = True\n",
    "        self._normalization_method = method\n",
    "\n",
    "    def _left_normalize(self, idx, max_bond):\n",
    "        \"\"\"\n",
    "        Normalize to left canonical form.\n",
    "\n",
    "        Input:\n",
    "        ------\n",
    "        idx: int    A site index which is used to stop\n",
    "                    the normalization process. The value of -1\n",
    "                    indicates a full propagations. Default: -1.\n",
    "        \"\"\"   \n",
    "        # determine where to stop\n",
    "        if idx == -1:\n",
    "            stop = self.size\n",
    "        else:\n",
    "            assert 0 < idx < self.size-1, 'The stoping site index must be 0 < idx < self.size-1'\n",
    "            stop = idx\n",
    "\n",
    "        # getting the cuttof dimension\n",
    "        max_bond = min(max_bond, self.bond_dim)\n",
    "\n",
    "        for i in range(stop):\n",
    "\n",
    "            # get the current tensor\n",
    "            M = self[i]\n",
    "\n",
    "            # reshape into a matrix by merging left/bottom legs\n",
    "            u, v, w = M.shape\n",
    "            M = M.reshape(u*v, w)\n",
    "\n",
    "            # perform SVD\n",
    "            U, s, Vh = jnp.linalg.svd(M, full_matrices=False)\n",
    "\n",
    "            # cutting off the bond dimension\n",
    "            U  = U[:,:max_bond]\n",
    "            Vh = Vh[:max_bond,:]\n",
    "\n",
    "            # calculating the discarded weight before shrinking\n",
    "            self.dw[i] = (s[max_bond:]**2).sum()\n",
    "            s  = s[:max_bond]\n",
    "\n",
    "            # storing the singular values\n",
    "            self.svs[i] = s\n",
    "\n",
    "            # assign the current tensor to U and reshape\n",
    "            self[i] = U.reshape(U.shape[0] // v, v, U.shape[1])\n",
    "                        \n",
    "            if i < self.size-1:\n",
    "                M_next = self[i+1].reshape(Vh.shape[1], -1)\n",
    "                self[i+1] = (jnp.diag(s) @ Vh @ M_next).reshape(U.shape[1], v, -1)\n",
    "            else:\n",
    "                self._norm = s**2\n",
    "\n",
    "        return\n",
    "\n",
    "    def _right_normalize(self, idx, max_bond):\n",
    "        \"\"\"\n",
    "        Normalize to right canonical form.\n",
    "\n",
    "        Input:\n",
    "        ------\n",
    "        idx: int    Index of the site indicating where to stop\n",
    "                    the normalization process. The value of -1\n",
    "                    indicate a full propagations. Default: -1.\n",
    "        \"\"\"\n",
    "        # assertions\n",
    "        if idx == -1:\n",
    "            stop = -1\n",
    "        else:\n",
    "            assert 0 < idx < self.size-1, 'The stoping index must be 0 < idx < self.size-1'\n",
    "            stop = idx\n",
    "\n",
    "        # getting the cuttof dimension\n",
    "        max_bond = min(max_bond, self.bond_dim)\n",
    "\n",
    "        for i in range(self.size-1, stop, -1):\n",
    "            M = self[i]\n",
    "            u, v, w = M.shape\n",
    "            M = M.reshape(u, v*w)\n",
    "\n",
    "            # perform SVD\n",
    "            U, s, Vh = jnp.linalg.svd(M, full_matrices=False)\n",
    "\n",
    "            # cutting off the bond dimension\n",
    "            U  = U[:,:max_bond]\n",
    "            Vh = Vh[:max_bond,:]\n",
    "\n",
    "            # calculating the discarded weight before shrinking\n",
    "            self.dw[i] = (s[max_bond:]**2).sum()\n",
    "            s  = s[:max_bond]\n",
    "\n",
    "            # storing the singular values\n",
    "            self.svs[i] = s\n",
    "\n",
    "            self[i] = Vh.reshape(Vh.shape[0], v, Vh.shape[1] // v)\n",
    "            if i > 0:\n",
    "                M_new = self[i-1].reshape(-1, U.shape[0])\n",
    "                self[i-1] = (M_new @ U @ jnp.diag(s)).reshape(-1, v, Vh.shape[0])\n",
    "            else:\n",
    "                self._norm = s**2\n",
    "\n",
    "        return\n",
    "    \n",
    "    def _site_normalize(self, idx, max_bond):\n",
    "        \"\"\"\n",
    "        Normalize to site canonical form.\n",
    "\n",
    "        Input:\n",
    "        ------\n",
    "        idx: int    Index of the site indicating where to stop\n",
    "                    the normalization process.\n",
    "        \"\"\"\n",
    "\n",
    "        self._left_normalize(idx, max_bond)\n",
    "        self._right_normalize(idx, max_bond)\n",
    "\n",
    "        return\n",
    "\n",
    "    def _bond_normalize(self, idx, max_bond):\n",
    "        \"\"\"\n",
    "        Normalize to bond canonical form.\n",
    "\n",
    "        Input:\n",
    "        ------\n",
    "        idx: int    Index of the site indicating where to stop\n",
    "                    the normalization process. The site with the\n",
    "                    index 'idx' is included to the left normalized\n",
    "                    part of the MPS, while the site with the index\n",
    "                    'idx+1' is included to the right normalized\n",
    "                    part of the MPS.\n",
    "        \"\"\"\n",
    "\n",
    "        self._left_normalize(idx, max_bond)\n",
    "        self._right_normalize(idx, max_bond)\n",
    "        \n",
    "        M = self[idx]\n",
    "        u, v, w = M.shape\n",
    "        M = M.reshape(u*v, w)\n",
    "\n",
    "        # perform SVD\n",
    "        U, s, Vh = jnp.linalg.svd(M, full_matrices=False)\n",
    "\n",
    "        # insert the bond singular values between idx and idx+1,\n",
    "        # shifting all to the right\n",
    "        self.svs[idx] = s\n",
    "\n",
    "        self[idx] = U.reshape(U.shape[0] // v, v, U.shape[1])\n",
    "\n",
    "        M_next = self[idx+1].reshape(Vh.shape[1], -1)\n",
    "        self[idx+1] = (Vh @ M_next).reshape(Vh.shape[0], v, -1)\n",
    "\n",
    "        return\n",
    "\n",
    "    def site_expectation(self, op, idx):\n",
    "        \"\"\"\n",
    "        Computing the expectation value of the operator.\n",
    "\n",
    "        Input:\n",
    "        ------\n",
    "        op:     Operator\n",
    "        \"\"\"\n",
    "        assert op.shape[0] == op.shape[1]\n",
    "        assert op.shape[0] == self[idx].shape[1]\n",
    "\n",
    "        self._site_normalize(idx, max_bond=jnp.inf)\n",
    "\n",
    "        M = self[idx]\n",
    "        A = jnp.tensordot(M.conj(), M, [[0, 2], [0, 2]])\n",
    "        \n",
    "        return jnp.trace(A @ op)\n",
    "\n",
    "    def entanglement_entropy(self, idx):\n",
    "        \"\"\"\n",
    "        Entanglement entropy calculation between sites idx and idx+1.\n",
    "        \"\"\"\n",
    "\n",
    "        self._bond_normalize(idx, max_bond=jnp.inf)\n",
    "        svs2 = jnp.square(self.svs[idx])\n",
    "\n",
    "        return -jnp.sum(svs2 * jnp.log2(svs2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "866e7d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = jax.random.PRNGKey(0)\n",
    "MPS_SIZE = 4\n",
    "LOCAL_DIM = 3\n",
    "BOND_DIM = 6 \n",
    "\n",
    "# Spliting the key\n",
    "key_mps, key_data, key_noise, key_run = jax.random.split(key, num=4)\n",
    "\n",
    "# target MPS model\n",
    "mps = random_mps(key_mps, size=MPS_SIZE, local_dim=LOCAL_DIM, bond_dim=BOND_DIM, dtype=jnp.complex128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "7ae36157",
   "metadata": {},
   "outputs": [],
   "source": [
    "mps.normalize('left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "6790baa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray(1.52819807, dtype=float64)"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mps.norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "85511de7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray(1.52819807-2.42861287e-17j, dtype=complex128)"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mps.get_overlap(mps.conjugate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "76d0d3e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, 'left', 1.528198068605834)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mps.is_normalized, mps._normalization_method, mps.norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "740bd3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_matrix(\n",
    "    key: PRNGKeyArray,\n",
    "    dim1: int,\n",
    "    dim2: Optional[int] = None,\n",
    "    dtype=jnp.complex128\n",
    "    ) -> DeviceArray:\n",
    "    \"\"\"\n",
    "    Genarate a random matrix of size (dim1, dim2).\n",
    "\n",
    "    Input:\n",
    "    ------\n",
    "    dim1:   First dimension.\n",
    "    dim2:   Second dimension. Optional, set to be\n",
    "            equal to the first dimension if not provided.\n",
    "    \"\"\"\n",
    "    if not dim2:\n",
    "        # generate a square matrix\n",
    "        dim2 = dim1\n",
    "    return jax.random.normal(key, (dim1, dim2), dtype=dtype)\n",
    "\n",
    "def random_unit_spectrum(\n",
    "    key: PRNGKeyArray,\n",
    "    dim1: int,\n",
    "    dim2: Optional[int]=None,\n",
    "    dtype=jnp.complex128\n",
    "    ) -> DeviceArray:\n",
    "    \"\"\"\n",
    "    Genarate a random matrix of size (dim1, dim2)\n",
    "    with a unit spectrum.\n",
    "\n",
    "    Input:\n",
    "    ------\n",
    "    dim1:   First dimension.\n",
    "    dim2:   Second dimension. Optional, set to be\n",
    "            equal to the first dimension if not provided.\n",
    "    \"\"\"\n",
    "    if not dim2:\n",
    "        dim2 = dim1\n",
    "    X = random_matrix(key, dim1, dim2, dtype=dtype)\n",
    "    U, _, Vh = jnp.linalg.svd(X, full_matrices=False)\n",
    "    return (U * jnp.ones(U.shape[1])) @ Vh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "1dceaa92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_mps(\n",
    "    key: PRNGKeyArray,\n",
    "    size: int,\n",
    "    local_dim: int,\n",
    "    bond_dim: int,\n",
    "    dtype=jnp.complex128) -> List[DeviceArray]:\n",
    "    \"\"\"\n",
    "    Generate a random MPS where each core tensor\n",
    "    is drawn i.i.d. from a uniform distribution \n",
    "    between -1 and 1.\n",
    "\n",
    "    Input:\n",
    "    ------\n",
    "    key:        The random key.\n",
    "    size:       The size (length) of an MPS.\n",
    "    local_dim:  The local dimension size.\n",
    "    bond_dim:   The bond dimension size.\n",
    "    dtype:      The type of data to return.\n",
    "    \"\"\"\n",
    "    # initialize MPS data collection\n",
    "    mps = MPS(size, local_dim, bond_dim)\n",
    "     \n",
    "    for i in range(size):\n",
    "        key, _ = jax.random.split(key)\n",
    "        if i == 0:  # left most tensor\n",
    "            tensor = random_unit_spectrum(key, local_dim, bond_dim, dtype=dtype)\n",
    "            tensor = tensor.reshape(1, local_dim, bond_dim)\n",
    "        elif i == size-1:  # right most tensor\n",
    "            tensor = random_unit_spectrum(key, bond_dim, local_dim, dtype=dtype)\n",
    "            tensor = tensor.reshape(bond_dim, local_dim, 1)\n",
    "        else:  # middle tensors\n",
    "            tensor = random_unit_spectrum(key, bond_dim*local_dim, bond_dim, dtype=dtype)\n",
    "            tensor = tensor.reshape(bond_dim, local_dim, bond_dim)\n",
    "        mps[i] = tensor\n",
    "    return mps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "33c0018a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray(1.47651315+1.04083409e-17j, dtype=complex128)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mps.norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1d897368",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'normalized'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-e02543087e3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'normalized'"
     ]
    }
   ],
   "source": [
    "mps.normalized()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13a8a3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dot(mps1: List[DeviceArray], mps2: List[DeviceArray]) -> jnp.double:\n",
    "    \"\"\"\n",
    "    Dot product of an MPS with another mps.\n",
    "    --A1----A2--...--An-- (MPS1)\n",
    "      |     |        |\n",
    "    \n",
    "      |     |        |\n",
    "    --B1----B2--...--Bn-- (MPS2)\n",
    "    \"\"\"\n",
    "    # contracts individual components\n",
    "    cdot = lambda x, y: jnp.einsum('pqr,uqv->purv', x, y)\n",
    "    # multiply two neighbouring tensors\n",
    "    mult = lambda x, y: jnp.einsum('purv,rvts->puts', x, y)\n",
    "    # contract all\n",
    "    res = reduce(mult, jax.tree_multimap(cdot, mps1, mps2))\n",
    "    return res.squeeze()\n",
    "\n",
    "def mps_norm(mps: List[DeviceArray]) -> jnp.double:\n",
    "    \"\"\"Computing the squared norm of an MPS\"\"\"\n",
    "    mps_conj = jax.tree_map(jnp.conj, mps)\n",
    "    return dot(mps, mps_conj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce30bab",
   "metadata": {},
   "source": [
    "## Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a096e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _random_sample(\n",
    "    key: PRNGKeyArray, \n",
    "    num_factors: int, \n",
    "    local_dim: int, \n",
    "    dtype=jnp.double) -> DeviceArray:\n",
    "    \"\"\"Generate a single sample with a number of factors\n",
    "    where each factor is generated from a Normal distribution.\n",
    "    \"\"\"\n",
    "    keys = jax.random.split(key, num=num_factors)\n",
    "    func = lambda k: jax.random.normal(k, (local_dim,), dtype)\n",
    "    return jax.vmap(func)(keys)\n",
    "\n",
    "def random_samples(\n",
    "    key: PRNGKeyArray, \n",
    "    sample_size: int, \n",
    "    num_factors: int, \n",
    "    local_dim: int, \n",
    "    dtype=jnp.double) -> DeviceArray:\n",
    "    \"\"\"Genarate random samples of a specific size\"\"\"\n",
    "    keys = jax.random.split(key, num=sample_size)\n",
    "    return jax.vmap(lambda k: _random_sample(k, num_factors, local_dim, dtype))(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "083c238f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_as_mps(sample: DeviceArray) -> List[DeviceArray]:\n",
    "    \"\"\"\n",
    "    Represent a data sample as an MPS. Useful for contracting with another MPS.\n",
    "    |    |    |       |        |     |     |          |\n",
    "    x1   x2   x3 ...  xn  => --x1----x2----x3-- ... --xn--\n",
    "    \"\"\"\n",
    "    return list(sample[:,jnp.newaxis,:,jnp.newaxis])\n",
    "\n",
    "def dot_samples(mps: List[DeviceArray], samples: DeviceArray) -> DeviceArray:\n",
    "    \"\"\"Apply dot product to many samples\"\"\"\n",
    "    return jax.vmap(lambda s: dot(mps,sample_as_mps(s)))(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ea78ab",
   "metadata": {},
   "source": [
    "# Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5dad16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_pkl(file_path: str, data: Any) -> None:\n",
    "    dir_name = os.path.dirname(file_path)\n",
    "    if not os.path.exists(dir_name):\n",
    "        os.makedirs(dir_name)\n",
    "    with open(file_path, 'wb') as f:\n",
    "        pickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "877c5c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def idict() -> DefaultDict:\n",
    "    \"\"\"Infinitely nested dict\"\"\"\n",
    "    return defaultdict(idict)\n",
    "\n",
    "def idict2dict(dic) -> Dict:\n",
    "    if isinstance(dic, defaultdict):\n",
    "        dic = {k: idict2dict(v) for k, v in dic.items()}\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70163d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dirs(root_dir: str, noise_level: float) -> None:\n",
    "    # A timestamp used in the experiments to store data\n",
    "    time_stamp = time.strftime('%Y%m%d', time.localtime())\n",
    "    exp_dir = os.path.join(f'{root_dir}/{time_stamp}-noise-{noise_level}')\n",
    "    lrn_dir = os.path.join(exp_dir, 'learning')  # stores the learning progress\n",
    "    res_dir = os.path.join(exp_dir, 'results')   # stores the experimenal results\n",
    "    for d in (lrn_dir, res_dir):\n",
    "        if not os.path.isdir(d):\n",
    "            os.makedirs(d)\n",
    "        elif len(os.listdir(d)) > 0:\n",
    "            raise FileExistsError(f'Directory {d} is not empty!')\n",
    "        else:\n",
    "            pass\n",
    "    return exp_dir, lrn_dir, res_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff981fb",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "076ed31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRNG seed\n",
    "SEED = 123\n",
    "\n",
    "# model size (MPS_SIZE * LOCAL_DIM * BOND_DIM ~ TRAIN_SIZE)\n",
    "MPS_SIZE = 4\n",
    "LOCAL_DIM = 4\n",
    "BOND_DIM = 8\n",
    "\n",
    "# data sample\n",
    "TRAIN_SIZE = 1000\n",
    "TEST_SIZE  = 5000\n",
    "\n",
    "# training params\n",
    "LEARNING_RATE = 1e-4\n",
    "\n",
    "# max num of epochs\n",
    "NUM_EPOCHS = int(1)\n",
    "\n",
    "# batch size\n",
    "BATCH_SIZE = 50\n",
    "\n",
    "# APPROX RANK\n",
    "APPROX_RANK = [16, 14, 12, 10, 8, 6, 4, 2]\n",
    "\n",
    "# NOISE MODEL\n",
    "PERCENT_NOISE = [0.1, 0.25, 0.5, 1, 5, 10] # noise level in percentages to the data std\n",
    "\n",
    "# SAVE/PRINT after that many epochs\n",
    "SAVE_AFTER_EPOCHS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "33d39be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_settings(settings_file):\n",
    "    with open(settings_file, 'w') as f:\n",
    "        txt = f\"\"\"\n",
    "SEED = {SEED}\n",
    "\n",
    "# model size (MPS_SIZE * LOCAL_DIM + BOND_DIM = TRAIN_SIZE)\n",
    "MPS_SIZE = {MPS_SIZE}\n",
    "LOCAL_DIM = {LOCAL_DIM}\n",
    "BOND_DIM = {BOND_DIM}\n",
    "\n",
    "# data sample\n",
    "TRAIN_SIZE = {TRAIN_SIZE}\n",
    "TEST_SIZE = {TEST_SIZE}\n",
    "\n",
    "# training params\n",
    "LEARNING_RATE = {LEARNING_RATE}\n",
    "\n",
    "# max num of epochs\n",
    "NUM_EPOCHS = {NUM_EPOCHS}\n",
    "\n",
    "# batch size\n",
    "BATCH_SIZE = {BATCH_SIZE}\n",
    "\n",
    "# APPROX RANK\n",
    "APPROX_RANK = {APPROX_RANK}\n",
    "\n",
    "# NOISE MODEL\n",
    "PERCENT_NOISE = {PERCENT_NOISE}\n",
    "\"\"\"\n",
    "        f.write(txt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2442e831",
   "metadata": {},
   "source": [
    "## Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a59c49ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = jax.random.PRNGKey(SEED)\n",
    "\n",
    "# Spliting the key\n",
    "key_params, key_data, key_noise, key_run = jax.random.split(key, num=4)\n",
    "\n",
    "# target MPS model\n",
    "true_params = random_mps(key_params, size=MPS_SIZE, local_dim=LOCAL_DIM, bond_dim=BOND_DIM)\n",
    "\n",
    "# generate samples\n",
    "data = random_samples(key_data, sample_size=TRAIN_SIZE+TEST_SIZE, num_factors=MPS_SIZE, local_dim=LOCAL_DIM)\n",
    "\n",
    "# train/test split\n",
    "train_data, test_data = data[:TRAIN_SIZE], data[TRAIN_SIZE:]\n",
    "\n",
    "# test targets\n",
    "test_targets = dot_samples(true_params, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e72d272",
   "metadata": {},
   "source": [
    "## Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "38565fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(params: List[DeviceArray], data: Tuple[DeviceArray, DeviceArray]) -> jnp.double:\n",
    "    inputs, targets = data\n",
    "    outputs = dot_samples(params, inputs)\n",
    "    err = jnp.subtract(targets, outputs)\n",
    "    return 0.5 * jnp.mean(jnp.log(jnp.power(err, 2) + 10))\n",
    "    # return jnp.sqrt(0.5 * jnp.mean(err))\n",
    "\n",
    "# computing the gradient wrt the loss\n",
    "grad_loss = jit(grad(loss, argnums=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7414cce",
   "metadata": {},
   "source": [
    "## Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fca895a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def update(i, opt_state, batch):\n",
    "    params = get_params(opt_state)\n",
    "    return opt_update(i, grad(loss)(params, batch), opt_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea50df95",
   "metadata": {},
   "source": [
    "## Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b4ccf660",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gauss_noise(key: PRNGKeyArray, sample_size: int, scale=1.0) -> DeviceArray:\n",
    "    return scale * jax.random.normal(key, shape=(sample_size,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ad5ef550",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = './experiment'\n",
    "\n",
    "# determining the step size for SGD\n",
    "num_complete_batches, leftover = divmod(TRAIN_SIZE, BATCH_SIZE)\n",
    "num_batches = num_complete_batches + bool(leftover)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a7a1050b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_iterator():\n",
    "    while True:\n",
    "        perm = jax.random.permutation(key_run, TRAIN_SIZE)\n",
    "        for i in range(num_batches):\n",
    "            batch_idx = perm[i * BATCH_SIZE:(i + 1) * BATCH_SIZE]\n",
    "            yield train_data[batch_idx], train_targets[batch_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1894f61a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximation rank: 16\n",
      "====================================================================================================\n",
      "Epoch: 0               \t|\t Train loss: 3.706      \t|\t Test loss: 3.693     \n",
      "----------------------------------------------------------------------------------------------------\n",
      "Time for rank 16: 2.12 sec\n",
      "Train loss: 3.71\n",
      "Test loss: 3.69\n",
      "====================================================================================================\n",
      "Approximation rank: 14\n",
      "====================================================================================================\n",
      "Epoch: 0               \t|\t Train loss: 3.547      \t|\t Test loss: 3.565     \n",
      "----------------------------------------------------------------------------------------------------\n",
      "Time for rank 14: 1.48 sec\n",
      "Train loss: 3.55\n",
      "Test loss: 3.56\n",
      "====================================================================================================\n",
      "Approximation rank: 12\n",
      "====================================================================================================\n",
      "Epoch: 0               \t|\t Train loss: 3.219      \t|\t Test loss: 3.242     \n",
      "----------------------------------------------------------------------------------------------------\n",
      "Time for rank 12: 1.41 sec\n",
      "Train loss: 3.22\n",
      "Test loss: 3.24\n",
      "====================================================================================================\n",
      "Approximation rank: 10\n",
      "====================================================================================================\n",
      "Epoch: 0               \t|\t Train loss: 3.199      \t|\t Test loss: 3.203     \n",
      "----------------------------------------------------------------------------------------------------\n",
      "Time for rank 10: 1.36 sec\n",
      "Train loss: 3.20\n",
      "Test loss: 3.20\n",
      "====================================================================================================\n",
      "Approximation rank: 8\n",
      "====================================================================================================\n",
      "Epoch: 0               \t|\t Train loss: 3.010      \t|\t Test loss: 3.075     \n",
      "----------------------------------------------------------------------------------------------------\n",
      "Time for rank 8: 0.46 sec\n",
      "Train loss: 3.01\n",
      "Test loss: 3.08\n",
      "====================================================================================================\n",
      "Approximation rank: 6\n",
      "====================================================================================================\n",
      "Epoch: 0               \t|\t Train loss: 2.723      \t|\t Test loss: 2.793     \n",
      "----------------------------------------------------------------------------------------------------\n",
      "Time for rank 6: 1.27 sec\n",
      "Train loss: 2.72\n",
      "Test loss: 2.79\n",
      "====================================================================================================\n",
      "Approximation rank: 4\n",
      "====================================================================================================\n",
      "Epoch: 0               \t|\t Train loss: 2.727      \t|\t Test loss: 2.746     \n",
      "----------------------------------------------------------------------------------------------------\n",
      "Time for rank 4: 1.25 sec\n",
      "Train loss: 2.73\n",
      "Test loss: 2.75\n",
      "====================================================================================================\n",
      "Approximation rank: 2\n",
      "====================================================================================================\n",
      "Epoch: 0               \t|\t Train loss: 2.696      \t|\t Test loss: 2.709     \n",
      "----------------------------------------------------------------------------------------------------\n",
      "Time for rank 2: 1.02 sec\n",
      "Train loss: 2.70\n",
      "Test loss: 2.71\n",
      "====================================================================================================\n",
      "Approximation rank: 16\n",
      "====================================================================================================\n",
      "Epoch: 0               \t|\t Train loss: 3.706      \t|\t Test loss: 3.693     \n",
      "----------------------------------------------------------------------------------------------------\n",
      "Time for rank 16: 0.08 sec\n",
      "Train loss: 3.71\n",
      "Test loss: 3.69\n",
      "====================================================================================================\n",
      "Approximation rank: 14\n",
      "====================================================================================================\n",
      "Epoch: 0               \t|\t Train loss: 3.546      \t|\t Test loss: 3.565     \n",
      "----------------------------------------------------------------------------------------------------\n",
      "Time for rank 14: 0.09 sec\n",
      "Train loss: 3.55\n",
      "Test loss: 3.56\n",
      "====================================================================================================\n",
      "Approximation rank: 12\n",
      "====================================================================================================\n",
      "Epoch: 0               \t|\t Train loss: 3.220      \t|\t Test loss: 3.242     \n",
      "----------------------------------------------------------------------------------------------------\n",
      "Time for rank 12: 0.09 sec\n",
      "Train loss: 3.22\n",
      "Test loss: 3.24\n",
      "====================================================================================================\n",
      "Approximation rank: 10\n",
      "====================================================================================================\n",
      "Epoch: 0               \t|\t Train loss: 3.199      \t|\t Test loss: 3.203     \n",
      "----------------------------------------------------------------------------------------------------\n",
      "Time for rank 10: 0.08 sec\n",
      "Train loss: 3.20\n",
      "Test loss: 3.20\n",
      "====================================================================================================\n",
      "Approximation rank: 8\n",
      "====================================================================================================\n",
      "Epoch: 0               \t|\t Train loss: 3.011      \t|\t Test loss: 3.075     \n",
      "----------------------------------------------------------------------------------------------------\n",
      "Time for rank 8: 0.08 sec\n",
      "Train loss: 3.01\n",
      "Test loss: 3.08\n",
      "====================================================================================================\n",
      "Approximation rank: 6\n",
      "====================================================================================================\n",
      "Epoch: 0               \t|\t Train loss: 2.723      \t|\t Test loss: 2.793     \n",
      "----------------------------------------------------------------------------------------------------\n",
      "Time for rank 6: 0.08 sec\n",
      "Train loss: 2.72\n",
      "Test loss: 2.79\n",
      "====================================================================================================\n",
      "Approximation rank: 4\n",
      "====================================================================================================\n",
      "Epoch: 0               \t|\t Train loss: 2.727      \t|\t Test loss: 2.746     \n",
      "----------------------------------------------------------------------------------------------------\n",
      "Time for rank 4: 0.08 sec\n",
      "Train loss: 2.73\n",
      "Test loss: 2.75\n",
      "====================================================================================================\n",
      "Approximation rank: 2\n",
      "====================================================================================================\n",
      "Epoch: 0               \t|\t Train loss: 2.697      \t|\t Test loss: 2.709     \n",
      "----------------------------------------------------------------------------------------------------\n",
      "Time for rank 2: 0.08 sec\n",
      "Train loss: 2.70\n",
      "Test loss: 2.71\n",
      "====================================================================================================\n",
      "Approximation rank: 16\n",
      "====================================================================================================\n",
      "Epoch: 0               \t|\t Train loss: 3.706      \t|\t Test loss: 3.693     \n",
      "----------------------------------------------------------------------------------------------------\n",
      "Time for rank 16: 0.09 sec\n",
      "Train loss: 3.71\n",
      "Test loss: 3.69\n",
      "====================================================================================================\n",
      "Approximation rank: 14\n",
      "====================================================================================================\n",
      "Epoch: 0               \t|\t Train loss: 3.546      \t|\t Test loss: 3.565     \n",
      "----------------------------------------------------------------------------------------------------\n",
      "Time for rank 14: 0.09 sec\n",
      "Train loss: 3.55\n",
      "Test loss: 3.56\n",
      "====================================================================================================\n",
      "Approximation rank: 12\n",
      "====================================================================================================\n",
      "Epoch: 0               \t|\t Train loss: 3.221      \t|\t Test loss: 3.242     \n",
      "----------------------------------------------------------------------------------------------------\n",
      "Time for rank 12: 0.09 sec\n",
      "Train loss: 3.22\n",
      "Test loss: 3.24\n",
      "====================================================================================================\n",
      "Approximation rank: 10\n",
      "====================================================================================================\n",
      "Epoch: 0               \t|\t Train loss: 3.198      \t|\t Test loss: 3.203     \n",
      "----------------------------------------------------------------------------------------------------\n",
      "Time for rank 10: 0.08 sec\n",
      "Train loss: 3.20\n",
      "Test loss: 3.20\n",
      "====================================================================================================\n",
      "Approximation rank: 8\n",
      "====================================================================================================\n",
      "Epoch: 0               \t|\t Train loss: 3.012      \t|\t Test loss: 3.075     \n",
      "----------------------------------------------------------------------------------------------------\n",
      "Time for rank 8: 0.08 sec\n",
      "Train loss: 3.01\n",
      "Test loss: 3.08\n",
      "====================================================================================================\n",
      "Approximation rank: 6\n",
      "====================================================================================================\n",
      "Epoch: 0               \t|\t Train loss: 2.724      \t|\t Test loss: 2.793     \n",
      "----------------------------------------------------------------------------------------------------\n",
      "Time for rank 6: 0.08 sec\n",
      "Train loss: 2.72\n",
      "Test loss: 2.79\n",
      "====================================================================================================\n",
      "Approximation rank: 4\n",
      "====================================================================================================\n",
      "Epoch: 0               \t|\t Train loss: 2.727      \t|\t Test loss: 2.746     \n",
      "----------------------------------------------------------------------------------------------------\n",
      "Time for rank 4: 0.07 sec\n",
      "Train loss: 2.73\n",
      "Test loss: 2.75\n",
      "====================================================================================================\n",
      "Approximation rank: 2\n",
      "====================================================================================================\n",
      "Epoch: 0               \t|\t Train loss: 2.697      \t|\t Test loss: 2.709     \n",
      "----------------------------------------------------------------------------------------------------\n",
      "Time for rank 2: 0.07 sec\n",
      "Train loss: 2.70\n",
      "Test loss: 2.71\n",
      "====================================================================================================\n",
      "Approximation rank: 16\n",
      "====================================================================================================\n",
      "Epoch: 0               \t|\t Train loss: 3.705      \t|\t Test loss: 3.693     \n",
      "----------------------------------------------------------------------------------------------------\n",
      "Time for rank 16: 0.09 sec\n",
      "Train loss: 3.71\n",
      "Test loss: 3.69\n",
      "====================================================================================================\n",
      "Approximation rank: 14\n",
      "====================================================================================================\n",
      "Epoch: 0               \t|\t Train loss: 3.545      \t|\t Test loss: 3.565     \n",
      "----------------------------------------------------------------------------------------------------\n",
      "Time for rank 14: 0.09 sec\n",
      "Train loss: 3.55\n",
      "Test loss: 3.56\n",
      "====================================================================================================\n",
      "Approximation rank: 12\n",
      "====================================================================================================\n",
      "Epoch: 0               \t|\t Train loss: 3.223      \t|\t Test loss: 3.242     \n",
      "----------------------------------------------------------------------------------------------------\n",
      "Time for rank 12: 0.08 sec\n",
      "Train loss: 3.22\n",
      "Test loss: 3.24\n",
      "====================================================================================================\n",
      "Approximation rank: 10\n",
      "====================================================================================================\n",
      "Epoch: 0               \t|\t Train loss: 3.198      \t|\t Test loss: 3.203     \n",
      "----------------------------------------------------------------------------------------------------\n",
      "Time for rank 10: 0.09 sec\n",
      "Train loss: 3.20\n",
      "Test loss: 3.20\n",
      "====================================================================================================\n",
      "Approximation rank: 8\n",
      "====================================================================================================\n",
      "Epoch: 0               \t|\t Train loss: 3.013      \t|\t Test loss: 3.075     \n",
      "----------------------------------------------------------------------------------------------------\n",
      "Time for rank 8: 0.08 sec\n",
      "Train loss: 3.01\n",
      "Test loss: 3.08\n",
      "====================================================================================================\n",
      "Approximation rank: 6\n",
      "====================================================================================================\n",
      "Epoch: 0               \t|\t Train loss: 2.727      \t|\t Test loss: 2.793     \n",
      "----------------------------------------------------------------------------------------------------\n",
      "Time for rank 6: 0.07 sec\n",
      "Train loss: 2.73\n",
      "Test loss: 2.79\n",
      "====================================================================================================\n",
      "Approximation rank: 4\n",
      "====================================================================================================\n",
      "Epoch: 0               \t|\t Train loss: 2.728      \t|\t Test loss: 2.746     \n",
      "----------------------------------------------------------------------------------------------------\n",
      "Time for rank 4: 0.07 sec\n",
      "Train loss: 2.73\n",
      "Test loss: 2.75\n",
      "====================================================================================================\n",
      "Approximation rank: 2\n",
      "====================================================================================================\n",
      "Epoch: 0               \t|\t Train loss: 2.699      \t|\t Test loss: 2.709     \n",
      "----------------------------------------------------------------------------------------------------\n",
      "Time for rank 2: 0.07 sec\n",
      "Train loss: 2.70\n",
      "Test loss: 2.71\n",
      "====================================================================================================\n",
      "Approximation rank: 16\n",
      "====================================================================================================\n",
      "Epoch: 0               \t|\t Train loss: 3.708      \t|\t Test loss: 3.693     \n",
      "----------------------------------------------------------------------------------------------------\n",
      "Time for rank 16: 0.08 sec\n",
      "Train loss: 3.71\n",
      "Test loss: 3.69\n",
      "====================================================================================================\n",
      "Approximation rank: 14\n",
      "====================================================================================================\n",
      "Epoch: 0               \t|\t Train loss: 3.551      \t|\t Test loss: 3.564     \n",
      "----------------------------------------------------------------------------------------------------\n",
      "Time for rank 14: 0.09 sec\n",
      "Train loss: 3.55\n",
      "Test loss: 3.56\n",
      "====================================================================================================\n",
      "Approximation rank: 12\n",
      "====================================================================================================\n",
      "Epoch: 0               \t|\t Train loss: 3.243      \t|\t Test loss: 3.242     \n",
      "----------------------------------------------------------------------------------------------------\n",
      "Time for rank 12: 0.08 sec\n",
      "Train loss: 3.24\n",
      "Test loss: 3.24\n",
      "====================================================================================================\n",
      "Approximation rank: 10\n",
      "====================================================================================================\n",
      "Epoch: 0               \t|\t Train loss: 3.221      \t|\t Test loss: 3.202     \n",
      "----------------------------------------------------------------------------------------------------\n",
      "Time for rank 10: 0.09 sec\n",
      "Train loss: 3.22\n",
      "Test loss: 3.20\n",
      "====================================================================================================\n",
      "Approximation rank: 8\n",
      "====================================================================================================\n",
      "Epoch: 0               \t|\t Train loss: 3.040      \t|\t Test loss: 3.075     \n",
      "----------------------------------------------------------------------------------------------------\n",
      "Time for rank 8: 0.08 sec\n",
      "Train loss: 3.04\n",
      "Test loss: 3.08\n",
      "====================================================================================================\n",
      "Approximation rank: 6\n",
      "====================================================================================================\n",
      "Epoch: 0               \t|\t Train loss: 2.773      \t|\t Test loss: 2.793     \n",
      "----------------------------------------------------------------------------------------------------\n",
      "Time for rank 6: 0.08 sec\n",
      "Train loss: 2.77\n",
      "Test loss: 2.79\n",
      "====================================================================================================\n",
      "Approximation rank: 4\n",
      "====================================================================================================\n",
      "Epoch: 0               \t|\t Train loss: 2.754      \t|\t Test loss: 2.746     \n",
      "----------------------------------------------------------------------------------------------------\n",
      "Time for rank 4: 0.07 sec\n",
      "Train loss: 2.75\n",
      "Test loss: 2.75\n",
      "====================================================================================================\n",
      "Approximation rank: 2\n",
      "====================================================================================================\n",
      "Epoch: 0               \t|\t Train loss: 2.730      \t|\t Test loss: 2.709     \n",
      "----------------------------------------------------------------------------------------------------\n",
      "Time for rank 2: 0.07 sec\n",
      "Train loss: 2.73\n",
      "Test loss: 2.71\n",
      "====================================================================================================\n",
      "Approximation rank: 16\n",
      "====================================================================================================\n",
      "Epoch: 0               \t|\t Train loss: 3.720      \t|\t Test loss: 3.694     \n",
      "----------------------------------------------------------------------------------------------------\n",
      "Time for rank 16: 0.08 sec\n",
      "Train loss: 3.72\n",
      "Test loss: 3.69\n",
      "====================================================================================================\n",
      "Approximation rank: 14\n",
      "====================================================================================================\n",
      "Epoch: 0               \t|\t Train loss: 3.575      \t|\t Test loss: 3.564     \n",
      "----------------------------------------------------------------------------------------------------\n",
      "Time for rank 14: 0.09 sec\n",
      "Train loss: 3.57\n",
      "Test loss: 3.56\n",
      "====================================================================================================\n",
      "Approximation rank: 12\n",
      "====================================================================================================\n",
      "Epoch: 0               \t|\t Train loss: 3.281      \t|\t Test loss: 3.242     \n",
      "----------------------------------------------------------------------------------------------------\n",
      "Time for rank 12: 0.09 sec\n",
      "Train loss: 3.28\n",
      "Test loss: 3.24\n",
      "====================================================================================================\n",
      "Approximation rank: 10\n",
      "====================================================================================================\n",
      "Epoch: 0               \t|\t Train loss: 3.253      \t|\t Test loss: 3.202     \n",
      "----------------------------------------------------------------------------------------------------\n",
      "Time for rank 10: 0.08 sec\n",
      "Train loss: 3.25\n",
      "Test loss: 3.20\n",
      "====================================================================================================\n",
      "Approximation rank: 8\n",
      "====================================================================================================\n",
      "Epoch: 0               \t|\t Train loss: 3.097      \t|\t Test loss: 3.076     \n",
      "----------------------------------------------------------------------------------------------------\n",
      "Time for rank 8: 0.08 sec\n",
      "Train loss: 3.10\n",
      "Test loss: 3.08\n",
      "====================================================================================================\n",
      "Approximation rank: 6\n",
      "====================================================================================================\n",
      "Epoch: 0               \t|\t Train loss: 2.856      \t|\t Test loss: 2.793     \n",
      "----------------------------------------------------------------------------------------------------\n",
      "Time for rank 6: 0.08 sec\n",
      "Train loss: 2.86\n",
      "Test loss: 2.79\n",
      "====================================================================================================\n",
      "Approximation rank: 4\n",
      "====================================================================================================\n",
      "Epoch: 0               \t|\t Train loss: 2.826      \t|\t Test loss: 2.746     \n",
      "----------------------------------------------------------------------------------------------------\n",
      "Time for rank 4: 0.08 sec\n",
      "Train loss: 2.83\n",
      "Test loss: 2.75\n",
      "====================================================================================================\n",
      "Approximation rank: 2\n",
      "====================================================================================================\n",
      "Epoch: 0               \t|\t Train loss: 2.814      \t|\t Test loss: 2.709     \n",
      "----------------------------------------------------------------------------------------------------\n",
      "Time for rank 2: 0.07 sec\n",
      "Train loss: 2.81\n",
      "Test loss: 2.71\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "for perc_noise in PERCENT_NOISE:\n",
    "    \n",
    "    # noise model\n",
    "    noise = gauss_noise(key_noise, sample_size=TRAIN_SIZE, scale=perc_noise * jnp.std(jnp.asarray(train_data)))\n",
    "\n",
    "    # generate outputs by contracting MPS with data\n",
    "    train_targets = dot_samples(true_params, train_data) + noise\n",
    "    \n",
    "    # making exp directory\n",
    "    exp_dir, lrn_dir, res_dir = make_dirs(root_dir, perc_noise)\n",
    "    \n",
    "    # storing the settings into a file\n",
    "    settings_file = os.path.join(exp_dir, 'settings.txt')\n",
    "    save_settings(settings_file)\n",
    "\n",
    "    # storing results\n",
    "    results = idict()\n",
    "\n",
    "    ref_loss_tr = jnp.inf\n",
    "    ref_loss_te = jnp.inf\n",
    "\n",
    "    for approx_rank in APPROX_RANK:\n",
    "    \n",
    "        # timer\n",
    "        tic = time.time()\n",
    "        \n",
    "        print(f'Approximation rank: {approx_rank}')\n",
    "        print('='*100)\n",
    "        \n",
    "        loss_tr = []\n",
    "        loss_te = []\n",
    "        \n",
    "        # get access to the data batches stream\n",
    "        batches = data_iterator()\n",
    "        \n",
    "        # params for the optimization\n",
    "        opt_init, opt_update, get_params = optimizers.adam(step_size=LEARNING_RATE)\n",
    "        \n",
    "        # initialize MPS parameters randomly but a different key is used from the true params\n",
    "        init_params = random_mps(key_run, size=MPS_SIZE, local_dim=LOCAL_DIM, bond_dim=approx_rank)\n",
    "        opt_state = opt_init(init_params)\n",
    "\n",
    "        # iteration counter\n",
    "        itercounter = itertools.count()\n",
    "            \n",
    "        # Main loop\n",
    "        for epoch in range(NUM_EPOCHS):\n",
    "\n",
    "            # update parameters\n",
    "            for _ in range(num_batches):\n",
    "                opt_state = update(next(itercounter), opt_state, next(batches))\n",
    "            \n",
    "            # get new params\n",
    "            params = get_params(opt_state)\n",
    "            \n",
    "            # Generalization risk\n",
    "            l_tr = loss(params, (train_data, train_targets))\n",
    "            l_te = loss(params, (test_data, test_targets))\n",
    "                    \n",
    "            # storing errors for statistics (saving memory)\n",
    "            loss_tr.append(l_tr)\n",
    "            loss_te.append(l_te)\n",
    "            \n",
    "            # printing epochs\n",
    "            if epoch % SAVE_AFTER_EPOCHS == 0:\n",
    "                \n",
    "                print(f'Epoch: {epoch:<15} \\t|\\t Train loss: {l_tr:<10.3f} \\t|\\t Test loss: {l_te:<10.3f}')\n",
    "            \n",
    "                # storing parameters during training\n",
    "                file_path = os.path.join(lrn_dir, f'./approx_rank_{approx_rank}/epoch_{epoch}.pkl')\n",
    "                save_pkl(file_path, params)\n",
    "            \n",
    "            # update the reference\n",
    "            ref_loss_tr = l_tr\n",
    "            ref_loss_te = l_te\n",
    "            \n",
    "        # storing train/test loss\n",
    "        results[\"train\"][approx_rank] = loss_tr\n",
    "        results[\"test\"][approx_rank] = loss_te\n",
    "\n",
    "        print('-'*100)\n",
    "        print(f'Time for rank {approx_rank}: {(time.time() - tic):0.2f} sec')\n",
    "        print(f'Train loss: {ref_loss_tr:0.2f}')\n",
    "        print(f'Test loss: {ref_loss_te:0.2f}')\n",
    "        print('='*100)\n",
    "        \n",
    "        file_path = os.path.join(res_dir, f'./approx_rank_{approx_rank}/loss.pkl')\n",
    "        save_pkl(file_path, idict2dict(results))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
