{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82c61e55",
   "metadata": {},
   "source": [
    "# Imports and settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "516a8cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36fb66c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: JAX_ENABLE_X64=1\n",
      "env: JAX_PLATFORM_NAME=cpu\n"
     ]
    }
   ],
   "source": [
    "%env JAX_ENABLE_X64=1\n",
    "%env JAX_PLATFORM_NAME=cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80210565",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import jit, grad\n",
    "from jax.example_libraries import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "933bc00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import time\n",
    "import itertools\n",
    "\n",
    "from collections import defaultdict\n",
    "from functools import reduce, partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b833c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, List, DefaultDict, Dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc61c86",
   "metadata": {},
   "source": [
    "## Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a90da14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# type alias\n",
    "PRNGKeyArray = Any\n",
    "DeviceArray = jnp.DeviceArray"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83f3f8e",
   "metadata": {},
   "source": [
    "# Random Data Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c26e10",
   "metadata": {},
   "source": [
    "## MPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "740bd3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_mps(\n",
    "    key: PRNGKeyArray,\n",
    "    size: int,\n",
    "    local_dim: int,\n",
    "    bond_dim: int,\n",
    "    dtype=jnp.double) -> List[jnp.DeviceArray]:\n",
    "    \"\"\"\n",
    "    Generate a random MPS where each core tensor\n",
    "    is drawn i.i.d. from a uniform distribution \n",
    "    between -1 and 1.\n",
    "\n",
    "    Input:\n",
    "    ------\n",
    "    key:        The random key.\n",
    "    size:       The size (length) of an MPS.\n",
    "    local_dim:  The local dimension size.\n",
    "    bond_dim:   The bond dimension size.\n",
    "    dtype:      The type of data to return.\n",
    "    \"\"\"\n",
    "    # initialize MPS data collection\n",
    "    mps = []\n",
    "     \n",
    "    for i in range(size):\n",
    "        key, _ = jax.random.split(key)\n",
    "        if i == 0:  # left most tensor\n",
    "            tensor = jax.random.uniform(\n",
    "                key, shape=(1, local_dim, bond_dim), minval=-1, maxval=1, dtype=dtype)\n",
    "        elif i == size-1:  # right most tensor\n",
    "            tensor = jax.random.uniform(\n",
    "                key, shape=(bond_dim, local_dim, 1), minval=-1, maxval=1, dtype=dtype)\n",
    "        else:  # middle tensors\n",
    "            tensor = jax.random.uniform(\n",
    "                key, shape=(bond_dim, local_dim, bond_dim), minval=-1, maxval=1, dtype=dtype)\n",
    "        mps.append(tensor)\n",
    "\n",
    "    return mps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76673883",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dot(mps1: List[jnp.DeviceArray], mps2: List[jnp.DeviceArray]) -> jnp.double:\n",
    "    \"\"\"\n",
    "    Dot product of an MPS with another mps.\n",
    "    --A1----A2--...--An-- (MPS1)\n",
    "      |     |        |\n",
    "    \n",
    "      |     |        |\n",
    "    --A1----A2--...--An-- (MPS2)\n",
    "    \"\"\"\n",
    "    # contracts individual components\n",
    "    dot = lambda x, y: jnp.einsum('pqr,uqv->purv', x, y)\n",
    "    # multiply two neighbouring tensors\n",
    "    mult = lambda x, y: jnp.einsum('purv,rvts->puts', x, y)\n",
    "    # contract all\n",
    "    res = reduce(mult, jax.tree_multimap(dot, mps1, mps2))\n",
    "    return res.squeeze()\n",
    "\n",
    "def mps_norm(mps: List[jnp.DeviceArray]) -> jnp.double:\n",
    "    \"\"\"Computing the squared norm of an MPS\"\"\"\n",
    "    mps_c = jax.tree_map(jnp.conj, mps)\n",
    "    return dot(mps, mps_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce30bab",
   "metadata": {},
   "source": [
    "## Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a096e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _random_sample(key: PRNGKeyArray, num_factors: int, local_dim: int) -> DeviceArray:\n",
    "    \"\"\"Generate a single sample with a number of factors\n",
    "    where each factor is generated from a Normal distribution.\n",
    "    \"\"\"\n",
    "    keys = jax.random.split(key, num=num_factors)\n",
    "    func = lambda k: jax.random.normal(k, (local_dim,), dtype)\n",
    "    return jax.vmap(func)(keys)\n",
    "\n",
    "def random_samples(key: PRNGKeyArray, sample_size: int, num_factors: int, local_dim: int) -> DeviceArray:\n",
    "    \"\"\"Genarate random samples of a specific size\"\"\"\n",
    "    keys = jax.random.split(key, num=sample_size)\n",
    "    return jax.vmap(lambda k: _random_sample(k, local_dim, num_factors))(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "083c238f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_as_mps(sample: DeviceArray) -> List[DeviceArray]:\n",
    "    \"\"\"\n",
    "    Represent a data sample as an MPS. Useful for contracting with another MPS.\n",
    "    |    |    |       |        |     |     |          |\n",
    "    x1   x2   x3 ...  xn  -> --x1----x2----x3-- ... --xn--\n",
    "    \"\"\"\n",
    "    return list(sample[:,jnp.newaxis,:,jnp.newaxis])\n",
    "\n",
    "def samples_dot(mps: List[jnp.DeviceArray], samples: jnp.DeviceArray) -> jnp.DeviceArray:\n",
    "    \"\"\"Apply dot product to many samples\"\"\"\n",
    "    return jax.vmap(lambda s: dot(mps,sample_as_mps(s)))(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ea78ab",
   "metadata": {},
   "source": [
    "# Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5dad16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_pkl(file_path: str, data: Any) -> None:\n",
    "    dir_name = os.path.dirname(file_path)\n",
    "    if not os.path.exists(dir_name):\n",
    "        os.makedirs(dir_name)\n",
    "    with open(file_path, 'wb') as f:\n",
    "        pickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877c5c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def idict() -> DefaultDict:\n",
    "    \"\"\"Infinitely nested dict\"\"\"\n",
    "    return defaultdict(idict)\n",
    "\n",
    "def idict2dict(dic) -> Dict:\n",
    "    if isinstance(dic, defaultdict):\n",
    "        dic = {k: idict2dict(v) for k, v in dic.items()}\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff981fb",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076ed31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRNG seed\n",
    "SEED = 161803\n",
    "\n",
    "# model size (MPS_SIZE * LOCAL_DIM + BOND_DIM = TRAIN_SIZE)\n",
    "MPS_SIZE = 15\n",
    "LOCAL_DIM = 3\n",
    "BOND_DIM = 6\n",
    "\n",
    "# data sample\n",
    "TRAIN_SIZE = 20\n",
    "TEST_SIZE  = 50\n",
    "\n",
    "# training params\n",
    "LEARNING_RATE = 1e-2\n",
    "\n",
    "# max num of epochs\n",
    "NUM_EPOCHS = 500\n",
    "\n",
    "# batch size\n",
    "BATCH_SIZE = 10\n",
    "\n",
    "# APPROX RANK\n",
    "APPROX_RANK = list(range(2,11,2))\n",
    "\n",
    "# NOISE MODEL\n",
    "PERCENT_NOISE = [0.1] #, 0.25, 0.5, 1, 5, 10] # noise level in percentages to the data std\n",
    "\n",
    "# SAVE/PRINT after that many epochs\n",
    "SAVE_AFTER_EPOCHS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d39be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_settings(settings_file):\n",
    "    if not os.path.exists(settings_file):\n",
    "        # storing for records\n",
    "        with open(settings_file, 'w') as f:\n",
    "            txt = f\"\"\"\n",
    "SEED = {SEED}\n",
    "\n",
    "# model size (MPS_SIZE * LOCAL_DIM + BOND_DIM = TRAIN_SIZE)\n",
    "MPS_SIZE = {MPS_SIZE}\n",
    "LOCAL_DIM = {LOCAL_DIM}\n",
    "BOND_DIM = {BOND_DIM}\n",
    "\n",
    "# data sample\n",
    "TRAIN_SIZE = {TRAIN_SIZE}\n",
    "TEST_SIZE = {TEST_SIZE}\n",
    "\n",
    "# training params\n",
    "LEARNING_RATE = {LEARNING_RATE}\n",
    "\n",
    "# max num of epochs\n",
    "NUM_EPOCHS = {NUM_EPOCHS}\n",
    "\n",
    "# batch size\n",
    "BATCH_SIZE = {BATCH_SIZE}\n",
    "\n",
    "# APPROX RANK\n",
    "APPROX_RANK = {APPROX_RANK}\n",
    "\n",
    "# NOISE MODEL\n",
    "PERCENT_NOISE = {PERCENT_NOISE}\n",
    "\"\"\"\n",
    "            f.write(txt)\n",
    "    else:\n",
    "        raise FileExistsError(f'File {settings_file} already exists - STOP!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70163d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dirs(root_dir, noise_level):\n",
    "    # A timestamp used in the experiments to store data\n",
    "    time_stamp = time.strftime('%Y%m%d', time.localtime())\n",
    "    exp_dir = os.path.join(f'{root_dir}/{time_stamp}-noise-{noise_level}')\n",
    "    lrn_dir = os.path.join(exp_dir, 'learning')  # stores the learning progress\n",
    "    res_dir = os.path.join(exp_dir, 'results')   # stores the experimenal results\n",
    "\n",
    "    for d in (lrn_dir, res_dir):\n",
    "        if not os.path.isdir(d):\n",
    "            os.makedirs(d)\n",
    "        elif len(os.listdir(d)) > 0:\n",
    "            raise FileExistsError(f'Directory {d} is not empty!')\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    return exp_dir, lrn_dir, res_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4a67c6",
   "metadata": {},
   "source": [
    "## Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38565fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(params, data):\n",
    "    inputs, targets = data\n",
    "    outputs = mdot(params, inputs)\n",
    "    err = jax.tree_multimap(jnp.subtract, targets, outputs)\n",
    "    return 0.5 * jnp.mean(jnp.log(jnp.power(err, 2) + 10))\n",
    "    # return jnp.sqrt(0.5 * jnp.mean(err)\n",
    "\n",
    "# computing the gradient wrt the loss\n",
    "# grad_loss = jit(grad(loss, argnums=0))\n",
    "grad_loss = grad(loss, argnums=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2442e831",
   "metadata": {},
   "source": [
    "## Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59c49ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = jax.random.PRNGKey(SEED)\n",
    "\n",
    "# Spliting the key\n",
    "key_params, key_data, key_noise, key_run = jax.random.split(key, num=4)\n",
    "\n",
    "# target MPS model\n",
    "true_params = random_mps(key_params, size=MPS_SIZE, local_dim=LOCAL_DIM, bond_dim=BOND_DIM)\n",
    "\n",
    "# generate samples\n",
    "data = random_sample(key_data, size=TRAIN_SIZE+TEST_SIZE, local_dim=LOCAL_DIM, n_factors=MPS_SIZE)\n",
    "\n",
    "# train/test split\n",
    "train_data, test_data = data[:TRAIN_SIZE], data[TRAIN_SIZE:]\n",
    "\n",
    "# test targets\n",
    "test_targets = mdot(true_params, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7414cce",
   "metadata": {},
   "source": [
    "# Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca895a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def update(i, opt_state, batch):\n",
    "    params = get_params(opt_state)\n",
    "    return opt_update(i, grad(loss)(params, batch), opt_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea50df95",
   "metadata": {},
   "source": [
    "## Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ccf660",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gauss_noise(key, sample_size, scale=1.0):\n",
    "    data =  scale * jax.random.normal(key, shape=(sample_size,))\n",
    "    return jax.tree_map(lambda x: jnp.asarray(x, dtype=jnp.double), data.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5ef550",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = './experiment'\n",
    "\n",
    "# determining the step size for SGD\n",
    "num_complete_batches, leftover = divmod(TRAIN_SIZE, BATCH_SIZE)\n",
    "num_batches = num_complete_batches + bool(leftover)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1894f61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for perc_noise in PERCENT_NOISE:\n",
    "    \n",
    "    # timer\n",
    "    tic = time.time()\n",
    "    \n",
    "    # noise model\n",
    "    noise = gauss_noise(key_noise, sample_size=TRAIN_SIZE, scale=perc_noise * jnp.std(jnp.asarray(train_data)))\n",
    "\n",
    "    # generate outputs by contracting MPS with data\n",
    "    train_targets = jax.tree_multimap(jnp.add, mdot(true_params, train_data), noise)\n",
    "    \n",
    "    # making exp directory\n",
    "    exp_dir, lrn_dir, res_dir = make_dirs(root_dir, perc_noise)\n",
    "    \n",
    "    # storing the settings into a file\n",
    "    settings_file = os.path.join(exp_dir, 'settings.txt')\n",
    "    save_settings(settings_file)\n",
    "\n",
    "    # storing results\n",
    "    results = idict()\n",
    "\n",
    "    ref_loss_tr = 1e6\n",
    "    ref_loss_te = 1e6\n",
    "\n",
    "    for approx_rank in APPROX_RANK:\n",
    "            \n",
    "        print(f'Approximation rank: {approx_rank}')\n",
    "        print('='*70)\n",
    "        \n",
    "        loss_tr = []\n",
    "        loss_te = []\n",
    "        \n",
    "        def data_iterator():\n",
    "            while True:\n",
    "                perm = jax.random.permutation(key_run, TRAIN_SIZE)\n",
    "                for i in range(num_batches):\n",
    "                    batch_idx = perm[i * BATCH_SIZE:(i + 1) * BATCH_SIZE]\n",
    "                    train_X, train_y = zip(*[(train_data[i], train_targets[i]) for i in batch_idx])\n",
    "                    yield train_X, train_y\n",
    "\n",
    "        batches = data_iterator()\n",
    "                \n",
    "        # params for the optimization (initial guess)\n",
    "        opt_init, opt_update, get_params = optimizers.adam(step_size=LEARNING_RATE)\n",
    "        \n",
    "        # initialize MPS parameters randomly but different SEED than was used for true params\n",
    "        init_params = random_mps(key_run, size=MPS_SIZE, local_dim=LOCAL_DIM, bond_dim=approx_rank)\n",
    "        opt_state = opt_init(init_params)\n",
    "\n",
    "        # counter\n",
    "        itercounter = itertools.count()\n",
    "            \n",
    "        # Looping until condition\n",
    "        for epoch in range(NUM_EPOCHS):\n",
    "\n",
    "            # update parameters\n",
    "            # params_new = line_search(params, (train_data, train_targets), LEARNING_RATE)\n",
    "            for _ in range(num_batches):\n",
    "                opt_state = update(next(itercounter), opt_state, next(batches))\n",
    "            \n",
    "            params = get_params(opt_state)\n",
    "            \n",
    "            # import pdb;pdb.set_trace()\n",
    "            \n",
    "            # Generalization risk\n",
    "            l_tr = loss(params, (train_data, train_targets))\n",
    "            l_te = loss(params, (test_data, test_targets))\n",
    "                    \n",
    "            # storing errors for statistics (saving memory)\n",
    "            loss_tr.append(l_tr)\n",
    "            loss_te.append(l_te)\n",
    "            \n",
    "            # printing epochs\n",
    "            if epoch % SAVE_AFTER_EPOCHS == 0:\n",
    "                \n",
    "                print(f'Epoch: {epoch:<15} \\t|\\t Train loss: {l_tr:<10.3f} \\t|\\t Test loss: {l_te:<10.3f}')\n",
    "            \n",
    "                # storing parameters during training\n",
    "                file_path = os.path.join(lrn_dir, f'./approx_rank_{approx_rank}/epoch_{epoch}.pkl')\n",
    "                save_pkl(file_path, params)\n",
    "            \n",
    "            # update the reference\n",
    "            ref_loss_tr = l_tr\n",
    "            ref_loss_te = l_te\n",
    "            \n",
    "        # storing train/test loss\n",
    "        results[\"train\"][approx_rank] = loss_tr\n",
    "        results[\"test\"][approx_rank] = loss_te\n",
    "\n",
    "        print('-'*100)\n",
    "        print(f'Time for rank {approx_rank}: {(time.time() - tic):0.2f} sec')\n",
    "        print(f'Train loss: {ref_loss_tr:0.2f}')\n",
    "        print(f'Test loss: {ref_loss_te:0.2f}')\n",
    "        print('='*100)\n",
    "        \n",
    "        file_path = os.path.join(res_dir, 'loss.pkl')\n",
    "        save_pkl(file_path, idict2dict(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6321180",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
