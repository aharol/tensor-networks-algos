{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About\n",
    "\n",
    "- `Main Author:` E. Miles Stoudenmire\n",
    "- `Source:` [ArXiv](https://arxiv.org/abs/1801.00315)\n",
    "- `Publish Date:` 31-12-2017\n",
    "- `Reviewed Date:` 07-06-2021\n",
    "\n",
    "## Citation\n",
    "\n",
    "```latex\n",
    "@article{stoudenmire2018learning,\n",
    "  title={Learning relevant features of data with multi-scale tensor networks},\n",
    "  author={Stoudenmire, E Miles},\n",
    "  journal={Quantum Science and Technology},\n",
    "  volume={3},\n",
    "  number={3},\n",
    "  pages={034003},\n",
    "  year={2018},\n",
    "  publisher={IOP Publishing}\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, Optional, Iterable, Callable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bitwise operations to determine powers of two"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below code is needed as the paper assumes the tree contains a number of nodes that is some power of two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_power_of_two(n: int) -> bool:\n",
    "    \"\"\"\n",
    "    Check if a given number is a power of two.\n",
    "    \"\"\"\n",
    "    return (n & (n-1) == 0) and n != 0\n",
    "\n",
    "def power_of_two(n: int) -> Tuple[int, int]:\n",
    "    \"\"\"\n",
    "    Given a number, returns it's previous \n",
    "    and next of keen which are powers of two.\n",
    "    \"\"\"\n",
    "    if is_power_of_two(n):\n",
    "        return n, n\n",
    "    count = 0    \n",
    "    while n != 0:\n",
    "        n >>= 1\n",
    "        count += 1\n",
    "    prec = 1 << (count-1)\n",
    "    succ = 1 << count\n",
    "    return prec, succ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "quickly checking..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, True, (128, 256))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_power_of_two(13), is_power_of_two(256), power_of_two(196)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The sliding window iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window(xs: np.ndarray,\n",
    "                   size: int, \n",
    "                   step: Optional[int]=1) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Sliding window iterator\n",
    "\n",
    "    Input:\n",
    "    ------\n",
    "    xs:             Iterable.\n",
    "    size:           Window size.\n",
    "    step:           Step size.\n",
    "    complement:     Whether to return a complement.\n",
    "    \n",
    "    Output:\n",
    "    -------\n",
    "    Iterable\n",
    "    \"\"\"\n",
    "    N = xs.size  # we assume that xs is 1D\n",
    "    chunks = int((N-size)/step + 1)\n",
    "    result = [xs[i*step:i*step+size] for i in range(chunks)]\n",
    "    return np.stack(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "quickly checking..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2] [2 3 4] [4 5 6] [6 7 8]\n"
     ]
    }
   ],
   "source": [
    "window_iterator = sliding_window(np.arange(10), size=3, step=2)\n",
    "print(*window_iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some linear algebra stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ishermitian(a: np.ndarray, rtol=1e-06, atol=1e-08) -> bool:\n",
    "    \"\"\"Check if the matrix is Hermitian\"\"\"\n",
    "    return np.allclose(a, a.conj().T, rtol=rtol, atol=atol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ispsd(a: np.ndarray) -> bool:\n",
    "    \"\"\"Check if a matrix is positive definite.\"\"\"\n",
    "    return np.all(np.linalg.eigvals(a) > 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist(data_path: str) -> np.ndarray:\n",
    "    num_labels = 10\n",
    "    img_size = 28\n",
    "\n",
    "    # data files\n",
    "    train_data_path = os.path.join(data_path, 'mnist_train.csv')\n",
    "    test_data_path = os.path.join(data_path, 'mnist_test.csv')\n",
    "\n",
    "    # loading data\n",
    "    train_data = np.loadtxt(train_data_path, delimiter=',')\n",
    "    test_data = np.loadtxt(test_data_path, delimiter=',')\n",
    "\n",
    "    # TLDR; scaling to [0.01, 0.99]; we want to avoid zeros and ones\n",
    "    # Longer answer: https://arxiv.org/pdf/1512.00567.pdf\n",
    "    frac = 0.99 / 255\n",
    "\n",
    "    # extracting data and labels\n",
    "    train_images = np.asfarray(train_data[:, 1:]) * frac + 0.01\n",
    "    train_labels = np.asfarray(train_data[:, :1])\n",
    "\n",
    "    test_images = np.asfarray(test_data[:, 1:]) * frac + 0.01\n",
    "    test_labels = np.asfarray(test_data[:, :1])\n",
    "\n",
    "    # transform labels into one hot representation\n",
    "    lr = np.arange(num_labels)\n",
    "    train_labels_one_hot = (lr==train_labels).astype(float)\n",
    "    test_labels_one_hot = (lr==test_labels).astype(float)\n",
    "\n",
    "    # we don't want zeroes and ones in the labels either\n",
    "    train_labels_one_hot[train_labels_one_hot==0] = 0.01\n",
    "    train_labels_one_hot[train_labels_one_hot==1] = 0.99\n",
    "    test_labels_one_hot[test_labels_one_hot==0] = 0.01\n",
    "    test_labels_one_hot[test_labels_one_hot==1] = 0.99\n",
    "\n",
    "    return {\n",
    "        'train': {\n",
    "            'images': train_images,\n",
    "            'labels': train_labels_one_hot\n",
    "        },\n",
    "        'test': {\n",
    "            'images': test_images,\n",
    "            'labels': test_labels_one_hot\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_mnist('../data/mnist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quickly checking that data is loaded correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfcAAAHwCAYAAAC7cCafAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAABYlAAAWJQFJUiTwAAAcgElEQVR4nO3dfbAldXkn8O8TSAEhgoBJrFQ2BRgEKiawjEECtbxNwqopFSLsmhelEk1FNq6ByJYmwThu3Ap/bHzFVRNNSLBqiYUVUxgCbgnKm5HKUISlMggGRjRRAdkZ3kbj4G//OD3JZHLvwJxz5va9v/P5VJ3qe7r7Of1M09zv/Z3Tp7taawEA+vFdYzcAAMyXcAeAzgh3AOiMcAeAzgh3AOiMcAeAzgh3AOiMcAeAzgh3AOiMcAeAzgh3AOiMcAeAzuw7dgN7Q1Xdn+SgJJtHbgUApnV4kkdba0fsaWGX4Z7koAMOOODQY4899tCxGwGAaWzatCnbtm2bqrbXcN987LHHHrpx48ax+wCAqaxbty6333775mlqR/3Mvap+qKr+qKr+saq+VVWbq+rdVXXImH0BwFo22si9qp6X5NYk35/kL5LcneTEJL+e5MVVdUpr7Rtj9QcAa9WYI/f/lUmwv7G1dnZr7S2ttTOTvCvJ0Un+x4i9AcCaNUq4D6P2szI5m/39uyx+W5Inkry6qg5c4dYAYM0b6235M4bpp1pr39l5QWvtsaq6JZPwPynJp5d7kapa7oy5Y+bSJQCsQWO9LX/0ML1nmeX3DtPnr0AvANCVsUbuBw/Trcss3zH/2bt7kdbauqXmDyP6E6bqDADWOJefBYDOjBXuO0bmBy+zfMf8LXu/FQDoy1jh/oVhutxn6kcN0+U+kwcAljFWuN8wTM+qqn/VQ1U9K8kpSZ5M8tcr3RgArHWjhHtr7e+TfCqTO9782i6L357kwCRXtNaeWOHWAGDNG/PGMf8lk8vPvreq1ifZlORFmXwH/p4kvz1ibwCwZo12tvwwen9hksszCfU3JXlekvckOcl15QFgOqPe8rW19uUkvzRmDwDQG99zB4DOCHcA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DO7Dt2A7Dovv71r09de91118207UsvvXTq2jPPPHOmbZ944okz1c/iF37hF2aq32effebUCewdRu4A0BnhDgCdEe4A0BnhDgCdEe4A0BnhDgCdEe4A0BnhDgCdEe4A0BnhDgCdEe4A0BnhDgCdEe4A0BnhDgCdEe4A0Bn3c4cZffKTn5yp/ud//uenrn3sscdm2vYsNm3aNFP9+9///jl1sudmvZf8McccM6dOYO8YbeReVZurqi3z+NpYfQHAWjf2yH1rkncvMf/xFe4DALoxdrhvaa1tGLkHAOiKE+oAoDNjj9z3q6pfTPLDSZ5IcmeSG1trT43bFgCsXWOH+3OTXLHLvPur6pdaa599uuKq2rjMIqeyArCwxnxb/o+TrM8k4A9M8mNJPpTk8CR/VVXHjdcaAKxdo43cW2tv32XWXUleX1WPJ3lTkg1Jznma11i31PxhRH/CHNoEgDVnNZ5Q98FheuqoXQDAGrUaw/2hYXrgqF0AwBq1GsP9pGF636hdAMAaNUq4V9WxVfVvRuZVdXiSy4anH13RpgCgE2OdUPefk7ypqm5M8qUkjyV5XpKfSbJ/kmuS/M+RegOANW2scL8hydFJ/n2SUzL5fH1Lkpsz+d77Fa21NlJvALCmjRLuwwVqnvYiNbAWrF+/fqb67/3e7526dsxbvq5lp5xyykz1n/3s9L++XvCCF8y0bXgmVuMJdQDADIQ7AHRGuANAZ4Q7AHRGuANAZ4Q7AHRGuANAZ4Q7AHRGuANAZ4Q7AHRGuANAZ4Q7AHRGuANAZ4Q7AHRGuANAZ0a5nzv05IADDpip/kMf+tDUtT/3cz8307afeOKJqWuPPPLImbZ93333zVQ/i0ceeWSm+quvvnrqWvdzZyUYuQNAZ4Q7AHRGuANAZ4Q7AHRGuANAZ4Q7AHRGuANAZ4Q7AHRGuANAZ4Q7AHRGuANAZ4Q7AHRGuANAZ4Q7AHTGLV9hZC972cumrj3uuONm2vatt946de1znvOcmbY95i1fZ/X6179+7BZgt4zcAaAzwh0AOiPcAaAzwh0AOiPcAaAzwh0AOiPcAaAzwh0AOiPcAaAzwh0AOiPcAaAzwh0AOiPcAaAzwh0AOiPcAaAz7ucOa9jv//7vz1R/8cUXT117yy23zLTttezb3/722C3Abhm5A0BnhDsAdEa4A0BnhDsAdEa4A0BnhDsAdEa4A0BnhDsAdEa4A0BnhDsAdEa4A0BnhDsAdEa4A0BnhDsAdMYtX2ENO+mkk2aqv/baa6eu/amf+qmZtv35z39+pvoxXXLJJVPX/sEf/MEcO4GlGbkDQGfmEu5VdW5Vva+qbqqqR6uqVdVHn6bm5Kq6pqoeqaptVXVnVV1YVfvMoycAWFTzelv+kiTHJXk8yVeSHLO7lavqFUk+nuSbSf4sySNJXpbkXUlOSXLenPoCgIUzr7flL0ry/CQHJblgdytW1UFJ/jDJU0lOb629trX235Icn+RzSc6tqlfNqS8AWDhzCffW2g2ttXtba+0ZrH5uku9LcmVr7W92eo1vZvIOQPI0fyAAAMsb44S6M4fpUqfp3pjkySQnV9V+K9cSAPRjjK/CHT1M79l1QWtte1Xdn+RHkxyZZNPuXqiqNi6zaLef+QNAz8YYuR88TLcus3zH/Gfv/VYAoD9r+iI2rbV1S80fRvQnrHA7ALAqjDFy3zEyP3iZ5Tvmb9n7rQBAf8YI9y8M0+fvuqCq9k1yRJLtSe5byaYAoBdjhPv1w/TFSyw7Ncn3JLm1tfatlWsJAPoxRrhfleThJK+qqhfumFlV+yd5x/D0AyP0BQBdmMsJdVV1dpKzh6fPHaY/WVWXDz8/3Fq7OElaa49W1a9kEvKfqaorM7n87Msz+ZrcVZlckhYAmMK8zpY/Psn5u8w7cngkyZeSXLxjQWvtE1V1WpLfTvLKJPsn+WKS30jy3md4pTsAYAlzCffW2oYkG/aw5pYkL53H9mFR3XjjjTPVz3JP9dtuu22mba9l69evH7sF2C33cweAzgh3AOiMcAeAzgh3AOiMcAeAzgh3AOiMcAeAzgh3AOiMcAeAzgh3AOiMcAeAzgh3AOiMcAeAzgh3AOjMvO7nDgvroYcemqn+rLPOmrr2rrvummnb27dvn6l+Uc3y3wxWgpE7AHRGuANAZ4Q7AHRGuANAZ4Q7AHRGuANAZ4Q7AHRGuANAZ4Q7AHRGuANAZ4Q7AHRGuANAZ4Q7AHRGuANAZ4Q7AHTG/dxhRvfff/9M9XfffffUte7HPo73vve9U9e+7W1vm2MnsDQjdwDojHAHgM4IdwDojHAHgM4IdwDojHAHgM4IdwDojHAHgM4IdwDojHAHgM4IdwDojHAHgM4IdwDojHAHgM645SvM6MQTT5yp/oorrpi69jWvec1M2962bdtM9YvqH/7hH8ZuAXbLyB0AOiPcAaAzwh0AOiPcAaAzwh0AOiPcAaAzwh0AOiPcAaAzwh0AOiPcAaAzwh0AOiPcAaAzwh0AOiPcAaAzwh0AOuN+7jCyc889d+rao446aqZtP/roozPVz+Kpp56aqf6cc86ZunbLli0zbRtWOyN3AOjMXMK9qs6tqvdV1U1V9WhVtar66DLrHj4sX+5x5Tx6AoBFNa+35S9JclySx5N8Jckxz6Dmb5N8Yon5d82pJwBYSPMK94syCfUvJjktyQ3PoOaO1tqGOW0fABjMJdxba/8c5lU1j5cEAKY05tnyP1hVv5rksCTfSPK51tqde/ICVbVxmUXP5GMBAOjSmOH+08Pjn1XVZ5Kc31p7YJSOAKADY4T7k0l+N5OT6e4b5v14kg1Jzkjy6ao6vrX2xNO9UGtt3VLzhxH9CfNoFgDWmhX/nntr7cHW2u+01m5vrW0ZHjcmOSvJ55P8SJLXrXRfANCLVXMRm9ba9iQfHp6eOmYvALCWrZpwHzw0TA8ctQsAWMNWW7ifNEzv2+1aAMCyVjzcq+qEqvo3262q9ZlcDCdJlrx0LQDw9OZytnxVnZ3k7OHpc4fpT1bV5cPPD7fWLh5+fmeSo6rq1kyuapdMzpY/c/j5ra21W+fRFwAsonl9Fe74JOfvMu/I4ZEkX0qyI9yvSHJOkp9I8pIk353k60k+luSy1tpNc+oJABbSvC4/uyGT76k/k3U/kuQj89guLLrjjjtu7Bam1lqbqf4d73jH1LVveMMbZtr2zTffPHXt1q1bZ9r2wQcfPFM9i2G1nVAHAMxIuANAZ4Q7AHRGuANAZ4Q7AHRGuANAZ4Q7AHRGuANAZ4Q7AHRGuANAZ4Q7AHRGuANAZ4Q7AHRGuANAZ+Z1P3eAPfLUU0/NVD/rbVtnsd9++01dW1Vz7ASWZuQOAJ0R7gDQGeEOAJ0R7gDQGeEOAJ0R7gDQGeEOAJ0R7gDQGeEOAJ0R7gDQGeEOAJ0R7gDQGeEOAJ0R7gDQGeEOAJ1xP3dgFO985zvHbmFqF1988dS1Bx100Bw7gaUZuQNAZ4Q7AHRGuANAZ4Q7AHRGuANAZ4Q7AHRGuANAZ4Q7AHRGuANAZ4Q7AHRGuANAZ4Q7AHRGuANAZ4Q7AHTGLV+Zm23bts1Uf8EFF0xd+8u//MszbfvUU0+dqX4RPf744zPV/97v/d6cOll5L33pS8duAXbLyB0AOiPcAaAzwh0AOiPcAaAzwh0AOiPcAaAzwh0AOiPcAaAzwh0AOiPcAaAzwh0AOiPcAaAzwh0AOiPcAaAzwh0AOuN+7szNm9/85pnq/+RP/mTq2jvuuGOmbX/sYx+buvY5z3nOTNs+9NBDp6798pe/PNO2N2/ePHXtb/7mb8607S1btsxUP4tLL710pvpnPetZc+oE9o6ZR+5VdVhVva6q/ryqvlhV26pqa1XdXFWvraolt1FVJ1fVNVX1yFBzZ1VdWFX7zNoTACyyeYzcz0vygSRfTXJDkgeS/ECSn03y4SQvqarzWmttR0FVvSLJx5N8M8mfJXkkycuSvCvJKcNrAgBTmEe435Pk5Un+srX2nR0zq+q3ktyW5JWZBP3Hh/kHJfnDJE8lOb219jfD/LcmuT7JuVX1qtbalXPoDQAWzsxvy7fWrm+tXb1zsA/zv5bkg8PT03dadG6S70ty5Y5gH9b/ZpJLhqcXzNoXACyqvX22/LeH6fad5p05TK9dYv0bkzyZ5OSq2m9vNgYAvdprZ8tX1b5JXjM83TnIjx6m9+xa01rbXlX3J/nRJEcm2fQ029i4zKJj9qxbAOjH3hy5X5rkBUmuaa1dt9P8g4fp1mXqdsx/9l7qCwC6tldG7lX1xiRvSnJ3klfvjW0kSWtt3TLb35jkhL21XQBYzeY+cq+qNyR5T5K/S3JGa+2RXVbZMTI/OEvbMX/LvHsDgEUw13CvqguTvC/JXZkE+9eWWO0Lw/T5S9Tvm+SITE7Au2+evQHAophbuFfVmzO5CM0dmQT7g8usev0wffESy05N8j1Jbm2tfWtevQHAIplLuA8XoLk0ycYk61trD+9m9auSPJzkVVX1wp1eY/8k7xiefmAefQHAIpr5hLqqOj/Jf8/kinM3JXljVe262ubW2uVJ0lp7tKp+JZOQ/0xVXZnJ5WdfnsnX5K7K5JK0AMAU5nG2/BHDdJ8kFy6zzmeTXL7jSWvtE1V1WpLfzuTytPsn+WKS30jy3p2vQw8A7JmZw721tiHJhinqbkny0lm3z+px4YUXzlR/7733Tl177bVLXfDwmTv66KOffqVlHHXUUTNt+0UvetHUtVdfffVM2966dbnLTex9S7zDt0eOP/74qWsvuuiimba9777uls3qtrcvPwsArDDhDgCdEe4A0BnhDgCdEe4A0BnhDgCdEe4A0BnhDgCdEe4A0BnhDgCdEe4A0BnhDgCdEe4A0BnhDgCdEe4A0Bk3JWZujjzyyJnqTzvttKlrL7jggpm2/YpXvGLq2lnuQz+P+rXqsMMOm6n+9ttvn1Mn0B8jdwDojHAHgM4IdwDojHAHgM4IdwDojHAHgM4IdwDojHAHgM4IdwDojHAHgM4IdwDojHAHgM4IdwDojHAHgM645Surxlve8papa7dv3z7Ttv/0T/90pvpZ3HbbbVPXXnbZZXPsZM8ccsghM9W7ZSvsPUbuANAZ4Q4AnRHuANAZ4Q4AnRHuANAZ4Q4AnRHuANAZ4Q4AnRHuANAZ4Q4AnRHuANAZ4Q4AnRHuANAZ4Q4AnRHuANCZaq2N3cPcVdXGE0444YSNGzeO3QoATGXdunW5/fbbb2+trdvTWiN3AOiMcAeAzgh3AOiMcAeAzgh3AOiMcAeAzgh3AOiMcAeAzgh3AOiMcAeAzgh3AOiMcAeAzgh3AOiMcAeAzgh3AOiMcAeAzswc7lV1WFW9rqr+vKq+WFXbqmprVd1cVa+tqu/aZf3Dq6rt5nHlrD0BwCLbdw6vcV6SDyT5apIbkjyQ5AeS/GySDyd5SVWd11pru9T9bZJPLPF6d82hJwBYWPMI93uSvDzJX7bWvrNjZlX9VpLbkrwyk6D/+C51d7TWNsxh+wDATmZ+W761dn1r7eqdg32Y/7UkHxyenj7rdgCAZ2YeI/fd+fYw3b7Esh+sql9NcliSbyT5XGvtzr3cDwB0b6+Fe1Xtm+Q1w9Nrl1jlp4fHzjWfSXJ+a+2BZ7iNjcssOuYZtgkA3dmbX4W7NMkLklzTWrtup/lPJvndJOuSHDI8TsvkZLzTk3y6qg7ci30BQNf2ysi9qt6Y5E1J7k7y6p2XtdYeTPI7u5TcWFVnJbk5yYuSvC7Je55uO621dctsf2OSE/a8cwBY++Y+cq+qN2QSzH+X5IzW2iPPpK61tj2Tr84lyanz7gsAFsVcw72qLkzyvky+q37GcMb8nnhomHpbHgCmNLdwr6o3J3lXkjsyCfYHp3iZk4bpffPqCwAWzVzCvaremskJdBuTrG+tPbybdU/Y9ZK0w/z1SS4ann50Hn0BwCKa+YS6qjo/yX9P8lSSm5K8sap2XW1za+3y4ed3Jjmqqm5N8pVh3o8nOXP4+a2ttVtn7QsAFtU8zpY/Ypjuk+TCZdb5bJLLh5+vSHJOkp9I8pIk353k60k+luSy1tpNc+gJABbWzOE+XB9+wx6s/5EkH5l1uwDA0tzPHQA6I9wBoDPCHQA6I9wBoDPCHQA6I9wBoDPCHQA6I9wBoDPCHQA6I9wBoDPCHQA6I9wBoDPCHQA6I9wBoDPCHQA6I9wBoDPCHQA6I9wBoDPCHQA6I9wBoDPCHQA6I9wBoDPCHQA6I9wBoDPCHQA6I9wBoDPCHQA6I9wBoDPCHQA6U621sXuYu6r6xgEHHHDoscceO3YrADCVTZs2Zdu2bY+01g7b09pew/3+JAcl2bzMKscM07tXpKE+2GfTsd+mY7/tOftsOqt5vx2e5NHW2hF7WthluD+dqtqYJK21dWP3slbYZ9Ox36Zjv+05+2w6ve43n7kDQGeEOwB0RrgDQGeEOwB0RrgDQGcW8mx5AOiZkTsAdEa4A0BnhDsAdEa4A0BnhDsAdEa4A0BnhDsAdGahwr2qfqiq/qiq/rGqvlVVm6vq3VV1yNi9rVbDPmrLPL42dn9jqapzq+p9VXVTVT067I+PPk3NyVV1TVU9UlXbqurOqrqwqvZZqb7Htif7raoO382x16rqypXufwxVdVhVva6q/ryqvjgcO1ur6uaqem1VLfl7fNGPtz3db70db/uO3cBKqarnJbk1yfcn+YtM7t17YpJfT/LiqjqltfaNEVtczbYmefcS8x9f4T5Wk0uSHJfJPvhK/uWe0Euqqlck+XiSbyb5sySPJHlZknclOSXJeXuz2VVkj/bb4G+TfGKJ+XfNr61V7bwkH0jy1SQ3JHkgyQ8k+dkkH07ykqo6r+10RTLHW5Ip9tugj+OttbYQjyTXJWlJ/usu8985zP/g2D2uxkeSzUk2j93HanskOSPJUUkqyenDMfTRZdY9KMmDSb6V5IU7zd8/kz84W5JXjf1vWoX77fBh+eVj9z3yPjszk2D+rl3mPzeTwGpJXrnTfMfbdPutq+NtId6WH0btZ2USVO/fZfHbkjyR5NVVdeAKt8Ya1Vq7obV2bxt+KzyNc5N8X5IrW2t/s9NrfDOTkWySXLAX2lx19nC/kaS1dn1r7erW2nd2mf+1JB8cnp6+0yLHW6bab11ZlLflzximn1riP/RjVXVLJuF/UpJPr3Rza8B+VfWLSX44kz+E7kxyY2vtqXHbWjPOHKbXLrHsxiRPJjm5qvZrrX1r5dpaM36wqn41yWFJvpHkc621O0fuabX49jDdvtM8x9vTW2q/7dDF8bYo4X70ML1nmeX3ZhLuz49wX8pzk1yxy7z7q+qXWmufHaOhNWbZ46+1tr2q7k/yo0mOTLJpJRtbI356ePyzqvpMkvNbaw+M0tEqUFX7JnnN8HTnIHe87cZu9tsOXRxvC/G2fJKDh+nWZZbvmP/svd/KmvPHSdZnEvAHJvmxJB/K5POpv6qq48Zrbc1w/E3nySS/m2RdkkOGx2mZnBx1epJPL/hHaZcmeUGSa1pr1+003/G2e8vtt66Ot0UJd6bUWnv78NnV11trT7bW7mqtvT6TExEPSLJh3A7pVWvtwdba77TWbm+tbRkeN2byLtvnk/xIkteN2+U4quqNSd6Uybd+Xj1yO2vG7vZbb8fbooT7jr9UD15m+Y75W/Z+K93YcULKqaN2sTY4/uaotbY9k68yJQt4/FXVG5K8J8nfJTmjtfbILqs43pbwDPbbktbq8bYo4f6FYfr8ZZYfNUyX+0yef+uhYbpm3qYa0bLH3/D53xGZnNhz30o2tcYt5PFXVRcmeV8m37k+Yzjze1eOt108w/22O2vueFuUcL9hmJ61xFWJnpXJRR2eTPLXK93YGnbSMF2YXxAzuH6YvniJZacm+Z4kty7wmcvTWLjjr6renMlFaO7IJKAeXGZVx9tO9mC/7c6aO94WItxba3+f5FOZnAT2a7ssfnsmf41d0Vp7YoVbW9Wq6tilTiCpqsOTXDY83e0lV0mSXJXk4SSvqqoX7phZVfsnecfw9ANjNLaaVdUJS11atarWJ7loeLoQx19VvTWTE8E2JlnfWnt4N6s73gZ7st96O95qUa4lscTlZzcleVEm34G/J8nJzeVn/5Wq2pDJySc3JvlSkseSPC/Jz2RytatrkpzTWvunsXocS1WdneTs4elzk/zHTP6qv2mY93Br7eJd1r8qk8uBXpnJ5UBfnsnXlq5K8p8W4cIue7Lfhq8fHZXJ/7dfGZb/eP7le9xvba3tCKtuVdX5SS5P8lQmby0vdRb85tba5TvVnJ0FP972dL91d7yNfYm8lXwk+XeZfLXrq0n+KZPAeneSQ8bubTU+MvkayP/O5MzSLZlc+OGhJP8nk++J1tg9jrhvNmRyqcrlHpuXqDklkz+I/l+SbUn+byYjgn3G/vesxv2W5LVJPpnJlSUfz+Ryqg9kcq30/zD2v2UV7bOW5DOOt9n2W2/H28KM3AFgUSzEZ+4AsEiEOwB0RrgDQGeEOwB0RrgDQGeEOwB0RrgDQGeEOwB0RrgDQGeEOwB0RrgDQGeEOwB0RrgDQGeEOwB0RrgDQGeEOwB0RrgDQGf+P3WPq0cgNsWbAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 248,
       "width": 251
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "j = 10   # a particularr image index\n",
    "img_vec = data['train']['images'][j]\n",
    "size = np.sqrt(img_vec.size).astype(int)\n",
    "img = img_vec.reshape(size, size)\n",
    "\n",
    "plt.imshow(img, cmap=\"Greys\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to rescale image so the size of eacch image is a power of $2$. This is required for the algorithm to work. First, we determine the nearest powers of $2$ given the size of each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The suggested new size is: 16.\n"
     ]
    }
   ],
   "source": [
    "j = 10   # a particularr image index\n",
    "img_vec = data['train']['images'][j]\n",
    "size_ = np.sqrt(img_vec.size).astype(int)\n",
    "size, _ = power_of_two(size_)   # returns nearest powers of 2\n",
    "\n",
    "print(f'The suggested new size is: {size}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we downscale each image to this new size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize(image_vec: np.ndarray, shape: Tuple[int,int]) -> np.ndarray:\n",
    "    orig_size = np.sqrt(img_vec.size).astype(int)\n",
    "    image = image_vec.reshape(orig_size, orig_size)\n",
    "    image = cv2.resize(image, shape, interpolation=cv2.INTER_CUBIC)\n",
    "    return image.reshape(-1,1)\n",
    "    \n",
    "new_shape = (8,8)  # I actually downscale even more to save exec time\n",
    "\n",
    "train_images = np.squeeze(np.apply_along_axis(lambda x: resize(x, new_shape), axis=1, arr=data['train']['images']))\n",
    "test_images = np.squeeze(np.apply_along_axis(lambda x: resize(x, new_shape), axis=1, arr=data['test']['images']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking if data is scaled properly by plotting random digits..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 144x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 139,
       "width": 136
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 144x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 139,
       "width": 136
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAREAAAEXCAYAAACKzXCTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAABYlAAAWJQFJUiTwAAAMOElEQVR4nO3df6yddX3A8fdnK3EdvxQytj/UAI3cQrottFthg1WQjMFMiDj8T7eQsUHGVlyI2eKiFhPBLJmW6baaOUW6/5aFODOUJkJk9UdKGprNTG7VtTKDZIptgcsFFT774zx3K7c9Ve7ne57z3NP3K7l5cp+n5/l+IeXN9zznOedEZiJJK/VT056ApNXNiEgqMSKSSoyIpBIjIqnEiEgqMSKSSoyIpBIjIqnEiEgqMSKSSoyIpJI1057AjxMRB4AzgINTnoo0y84Fns7M817pAwcfEeCMtWvXnjU3N3fWtCcizar5+XkWFxdX9NjVEJGDc3NzZ+3evXva85Bm1uWXX86+ffsOruSxXhORVGJEJJUYEUklRkRSiRGRVNIsIhHx2oj4REQ8EREvRMTBiNgeEa9pNYak4WnyEm9ErAO+BJwDfBp4DNgM3AZcExGXZeZTLcaSNCytViJ/yyggWzPzLZn555n5JuDDwBzwgUbjSBqYckS6VcjVjG5L/5tlh98HLADviIhTq2NJGp4WK5Eru+2uzHzp6AOZ+QzwReBngUsbjCVpYFpEZK7b7h9z/Ovd9oIGY0kamBYXVs/stkfGHF/a/+oTnSQi9o45tH4Fc5LUE+8TkVTSYiWytNI4c8zxpf2HT3SSzNx0vP3dCmXjimYmaeJarETmu+24ax5v6LbjrplIWsVaROShbnt1RLzsfBFxOnAZ8BzwlQZjSRqYckQy85vALkYfr3brssN3AKcCOzNzoTqWpOFp9clmf8Totve/joirgK8BlzC6h2Q/8BeNxpE0ME1enelWI78C3MMoHrcD64C7gUt934w0u5p9xmpm/jdwY6vzSVodvE9EUokRkVRiRCSVGBFJJUZEUslq+AY8NXLKKaf0Ntb555/f21gLC/3dx3jo0KHexoJ+/9lWypWIpBIjIqnEiEgqMSKSSoyIpBIjIqnEiEgqMSKSSoyIpBIjIqnEiEgqMSKSSoyIpBIjIqnEiEgqMSKSSoyIpBIjIqnEiEgqMSKSSoyIpBIjIqnEiEgqMSKSSoyIpBIjIqnEr9E8iezYsaO3sQ4cONDbWJs3b+5tLB3LlYikEiMiqcSISCoxIpJKjIikEiMiqcSISCopRyQizo6ImyLivoj4RkQsRsSRiNgdEb8fEYZKmmEtbjZ7G/B3wHeAh4DHgZ8H3gp8HLg2It6WmdlgLEkD0yIi+4HrgH/NzJeWdkbEu4E9wO8wCso/NxhL0sCUn2pk5oOZ+ZmjA9LtfxJYus/6iuo4koZp0tcrfthtfzThcSRNycTegBcRa4Df7X793E/w5/eOObS+2aQkNTfJlcgHgQ3A/Zn5wATHkTRFE1mJRMRW4HbgMeAdP8ljMnPTmHPtBTa2m52klpqvRCLij4G7gf8ErszM77ceQ9JwNI1IRLwT+AjwVUYBebLl+SUNT7OIRMSfAR8G9jEKyP+0Orek4WoSkYh4D6MLqXuBqzLzey3OK2n4yhdWI+L3gPcDLwL/BmyNiOV/7GBm3lMdS9LwtHh15rxu+9PAO8f8mS8A9zQYS9LAtLjtfVtmxo/5uaLBXCUNkG/Tl1RiRCSVGBFJJUZEUokRkVTid/GeRG6++ebextqwYUNvY91www29jbWwsNDbWKuFKxFJJUZEUokRkVRiRCSVGBFJJUZEUokRkVRiRCSVGBFJJUZEUokRkVRiRCSVGBFJJUZEUokRkVRiRCSVGBFJJUZEUokRkVRiRCSVGBFJJUZEUokRkVRiRCSVGBFJJUZEUolfozlFi4uLvY63devW3sa68847exvr8OHDvY2lY7kSkVRiRCSVGBFJJUZEUokRkVRiRCSVTCwiEfH2iMju56ZJjSNpuiYSkYh4HfBR4NlJnF/ScDSPSEQE8EngKWBH6/NLGpZJrES2Am8CbgQWJnB+SQPSNCIRcSHwQeDuzHy45bklDVOz985ExBpgJ/A48O4VPH7vmEPrK/OSNFkt34D3XuBi4PLM7PedZZKmpklEIuISRquPv8rML6/kHJm5acy59wIbC9OTNEHlayLd05h7gf3Ae8ozkrSqtLiwehpwAXAh8PxRN5gl8L7uz/x9t297g/EkDUiLpzMvAP8w5thGRtdJdgPzwIqe6kgarnJEuouox72tPSK2MYrIpzLz49WxJA2Pb8CTVGJEJJVMNCKZuS0zw6cy0uxyJSKpxIhIKjEikkqMiKQSIyKpxK/RXGbNmv7+lZx22mm9jQVw77339jbWtdde29tYd911V29j6ViuRCSVGBFJJUZEUokRkVRiRCSVGBFJJUZEUokRkVRiRCSVGBFJJUZEUokRkVRiRCSVGBFJJUZEUokRkVRiRCSVGBFJJUZEUokRkVRiRCSVGBFJJUZEUokRkVRiRCSVGBFJJX6N5jJbtmzpbaw9e/b0NhbARRdd1NtYjzzySG9jZWZvY+lYrkQklRgRSSVGRFKJEZFUYkQklRgRSSVGRFJJ04hExFURcV9EPBkRL0TEExHxQET8dstxJA1Hs5vNIuIvgXcB3wb+Bfge8HPAJuAK4P5WY0kajiYRiYg/YBSQTwF/mJk/WHb8lBbjSBqe8tOZiHgV8AHgcY4TEIDM/GF1HEnD1GIl8puMnrZsB16KiDcDG4DngT2Z+eUGY0gaqBYR+dVu+zzwKKOA/J+IeBi4ITO/e6KTRMTeMYfWl2coaWJavDpzTrd9F5DAbwCnA78E7AK2AP/UYBxJA9RiJbIUoh8B12Xmwe73/4iI64F54I0R8WsnemqTmZuOt79boWxsME9JE9BiJXK42z56VEAAyMzngAe6Xzc3GEvSwLSIyHy3PTzm+KFuu7bBWJIGpkVEPs/oWshFEXG88y1daD3QYCxJA1OOSGZ+C/gM8HrgtqOPRcTVwG8xWqV8rjqWpOFpddv7rcDFwIe6+0QeBc4D3gK8CNyUmUcajSVpQJpEJDO/HRGbgPcC1zF6WfdpRiuUuzKz308kltSbZm/A624m+5PuR9JJws8TkVRiRCSVGBFJJUZEUokRkVTid/Eu8+CDD057CjPB78c9ebgSkVRiRCSVGBFJJUZEUokRkVRiRCSVGBFJJUZEUokRkVRiRCSVGBFJJUZEUokRkVRiRCSVGBFJJUZEUokRkVRiRCSVGBFJJUZEUokRkVRiRCSVGBFJJUZEUokRkVQSQ/+msoh4au3atWfNzc1NeyrSzJqfn2dxcfH7mXn2K33saojIAeAM4OArfOj6bvtY0wlpVvj34+XOBZ7OzPNe6QMHH5GVioi9AJm5adpz0fD496Mdr4lIKjEikkqMiKQSIyKpxIhIKpnZV2ck9cOViKQSIyKpxIhIKjEikkqMiKQSIyKpxIhIKpm5iETEayPiExHxRES8EBEHI2J7RLxm2nPTdHV/F3LMz5PTnt9qtWbaE2gpItYBXwLOAT7N6LMiNgO3AddExGWZ+dQUp6jpOwJsP87+Z3uex8yYqTtWI+IB4Gpga2Z+5Kj9HwL+FPhYZt4yrflpuiLiIEBmnjvdmcyWmYlItwr5BqNPQFuXmS8ddex04DtAAOdk5sJUJqmpMiKTMUtPZ67struODghAZj4TEV9ktEq5FPh835PTYLwqIt4OvB5YAP4deDgzX5zutFavWYrI0ic57x9z/OuMInIBRuRk9gvAzmX7DkTEjZn5hWlMaLWbpVdnzuy2R8YcX9r/6slPRQP1SeAqRiE5FfhF4GOMPqT4sxHxy9Ob2uo1SysR6YQy845lu74K3BIRzwK3A9uA6/ue12o3SyuRpZXGmWOOL+0/PPmpaJXZ0W23THUWq9QsRWS+214w5vgbuu24ayY6eX2325461VmsUrMUkYe67dUR8bJ/ru4l3suA54Cv9D0xDd6l3fa/pjqLVWpmIpKZ3wR2MbpIduuyw3cw+r/MTu8ROTlFxIURccxKIyLOBT7a/fqPvU5qRszMzWZw3NvevwZcwugekv3Ar3vb+8kpIrYxunj6MPAt4BlgHfBm4GeA+4HrM/MH05rjajVTEQGIiNcB7weuAc5mdKfqfcAdmXlomnPT9ETEG4FbgIv5/5d4DwP7GN03sjNn7T+GnsxcRCT1a2auiUiaDiMiqcSISCoxIpJKjIikEiMiqcSISCoxIpJKjIikEiMiqcSISCoxIpJKjIikEiMiqcSISCoxIpJKjIikkv8FRwOC6Mv2dpMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 144x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 139,
       "width": 136
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 144x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 139,
       "width": 136
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_digit(image_vec: np.ndarray) -> None:\n",
    "    assert image_vec.ndim == 1\n",
    "    size = np.sqrt(image_vec.size).astype(int)\n",
    "    plt.rcParams[\"figure.figsize\"] = (2,2)\n",
    "    plt.imshow(image_vec.reshape(size, size), cmap=\"Greys\")\n",
    "    plt.show()\n",
    "\n",
    "digits_idx = (0,23,157,996)    # plot random images\n",
    "for j in digits_idx:\n",
    "    show_digit(train_images[j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feature map $\\Phi(\\bf x)$ maps inpunt data vector $\\bf x$ from a space of dimension $N$ to a space of dimension $d^N$, i.e. each component of the input vector $x_j$ is mapped into a $d$-dimensional vector. See Eq. 8 in text.\n",
    "\n",
    "The tensor $\\Phi^{s_1 s_2 \\cdots s_N}$ is the tensor productof the local feature maps $\\Phi^{s_j}(x_j)$ applied to each input $x_j$ along the indices $s_j = 1,2,\\cdots,N$. The local feature map is required to have unit norm analogous to the wave function norm, otherwise the tensor networks are not guaranteed to be numerically stable.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "FMap = Callable[np.ndarray, np.ndarray] # type alias\n",
    "\n",
    "def feature_map(xs: Iterable, \n",
    "                f: FMap,\n",
    "                *fs: Iterable[FMap],\n",
    "                acc: Optional[np.ndarray]=None) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Feature mapping for a single data sample (image vector).\n",
    "    Input:\n",
    "    ------\n",
    "\n",
    "    Output:\n",
    "    -------\n",
    "    An array containing feature values for each vector value.\n",
    "    The size of the output is features x vector\n",
    "    \"\"\"\n",
    "    vf = np.vectorize(f)\n",
    "    acc = vf(xs) if acc is None else np.r_[acc, vf(xs)]\n",
    "    if fs:\n",
    "        yield from feature_map(xs, *fs, acc=acc)\n",
    "    else:\n",
    "        yield acc\n",
    "\n",
    "def tensorize_dataset(a: np.ndarray, *fs: Iterable[FMap]) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    The tensorization of the dataset.\n",
    "    Input:\n",
    "    ------\n",
    "    a:      Dataset containing images with pixels aranged as a long vector.\n",
    "    fs:     Features\n",
    "\n",
    "    Output:\n",
    "    -------\n",
    "    \"\"\"\n",
    "    n,m = a.shape\n",
    "    # feature extractor iterator\n",
    "    feat_extractor_iterator = feature_map(a,*fs)\n",
    "    # creating features\n",
    "    phi = np.vstack(*feat_extractor_iterator)\n",
    "    # rearranging features for convenience\n",
    "    return phi.reshape(len(fs),n,m).transpose(0,2,1)\n",
    "\n",
    "features = [\n",
    "    lambda _: 1,\n",
    "    lambda x: x,\n",
    "]\n",
    "# features = [\n",
    "#   lambda x: np.cos( (np.pi/2) * x ),\n",
    "#   lambda x: np.sin( (np.pi/2) * x ),\n",
    "# ]\n",
    "phi_train = tensorize_dataset(train_images, *features)\n",
    "phi_test = tensorize_dataset(test_images, *features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 64, 60000)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phi_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizing the features so we can trivially contract them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def normalize_along_axis(a: np.ndarray, \n",
    "#                          ord: Optional[int] = 2,\n",
    "#                          axis: Optional[int] = -1) -> np.ndarray:\n",
    "#     z = np.atleast_1d(np.linalg.norm(a, ord, axis))\n",
    "#     z[z==0] = 1\n",
    "#     return a / np.expand_dims(z, axis)\n",
    "#\n",
    "#Phi = normalize_along_axis(phi_train, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "checking the normalization on a random sample of features and images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_size = 10\n",
    "#\n",
    "# for i in range(sample_size):\n",
    "#     m = np.random.choice(phi_train.shape[1])\n",
    "#     n = np.random.choice(phi_train.shape[2])\n",
    "#     assert np.allclose(phi_train[:,m,n].T @ phi_train[:,m,n], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking if images are correctly processed..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 144x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 139,
       "width": 136
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 144x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 139,
       "width": 136
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "j = 157                       # specific image id\n",
    "img = phi_train[:,:,j]        # each image is a (1,x) represenattion\n",
    "show_digit(train_images[j])   # original image\n",
    "show_digit(img[1,:])          # image asfter the feature map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing the reduced covariance matrix and truncate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncate_covariance(a: np.ndarray,\n",
    "                        eps: Optional[float]=1e-3) -> Tuple[np.ndarray, np.ndarray]:\n",
    "\n",
    "    \"\"\"\n",
    "    Approximate the input covariance matrix by a truncated version.\n",
    "    Uses the eigendecomposition to diagonaize the input matrix\n",
    "    and truncates the spectrum p that satisfies the condition\n",
    "    sum(p)/trace(a) < eps.\n",
    "\n",
    "    Input:\n",
    "    ------\n",
    "    a:      Matrix to be truncated.\n",
    "    eps:    The truncation error.\n",
    "\n",
    "    Output:\n",
    "    -------\n",
    "    p:      The remaining spectrum.\n",
    "    U:      The eigenvectors corresponding to p.\n",
    "    D:      The index of the smallest non-negligible eigenalue.\n",
    "    \"\"\"\n",
    "    assert ishermitian(a), 'Input matrix is not Hermitian.'    \n",
    "    # the eignevalue decomposition\n",
    "    p, U = np.linalg.eigh(a)  # p are sorted in ascending order\n",
    "    # checking the contribution of eignevalues and get the index D\n",
    "    err = np.cumsum(p / np.trace(a))  # errors see Eq. (19) in text\n",
    "    idx = np.amin(np.where(err >= np.complex64(eps))[0])  # non-negligible errros\n",
    "    return p, U, idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "quickly checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(111)\n",
    "v = np.random.rand(30,10) + 1j*np.random.rand(30,10)\n",
    "a = v @ v.conj().T  # covariance matrix\n",
    "\n",
    "p,U,D = truncate_covariance(a)\n",
    "assert np.allclose((U[:,D:] * p[D:]) @ U[:,D:].conj().T, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def go(a: np.ndarray, eps: Optional[float]=1e-3) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    A single step building a tree layer.\n",
    "\n",
    "    Input:\n",
    "    ------\n",
    "    a:      Array of input data used to construct the isometries.\n",
    "    eps:    Truncation tolerance.\n",
    "\n",
    "    Output:\n",
    "    -------\n",
    "    A tensor representing the isometries.\n",
    "    \"\"\"\n",
    "    # getting the shape of the input tensor\n",
    "    u,v,w = a.shape\n",
    "    # precomputes all density matrices\n",
    "    rho = np.einsum('ilj,klj->iklj', a, a.conj())\n",
    "    # initialize the isometries\n",
    "    isometries  = np.empty(shape=(u**2, u**2, 0), dtype=np.double)\n",
    "    # initialize the trancation idices for each isometry\n",
    "    indices = np.empty(shape=(v//2, 0), dtype=int)\n",
    "\n",
    "    # gets the sliding window iterator\n",
    "    iterator = sliding_window(np.arange(v), step=2, size=2)\n",
    "    \n",
    "    for i,j in iterator:\n",
    "\n",
    "        if i == 0:\n",
    "            # an edge case\n",
    "            left = np.ones(w)\n",
    "        else:\n",
    "            # contraction of all parts to the left of the pointer (i.e. l)\n",
    "            left = np.einsum('ikj,ikj->j', a[:,:i,:], a[:,:i,:].conj())\n",
    "\n",
    "        if j == v-1:\n",
    "            # an edge case\n",
    "            right = np.ones(w)\n",
    "        else:\n",
    "            # contraction all parts to the right of the pointer (i.e. r+1)\n",
    "            right = np.einsum('ikj,ikj->j', a[:,j+1:,:], a[:,j+1:,:].conj())\n",
    "\n",
    "        # reduced density matrix for the window\n",
    "        rho_ij = np.einsum('ikj,mnj->imknj', rho[:,:,i,:], rho[:,:,j,:])\n",
    "        # scaled by left and right parts (aka reduced density matrix)\n",
    "        rho_ij = np.einsum('...j,...j,...j', left, rho_ij, right)\n",
    "        \n",
    "        # eigen decomposition\n",
    "        _, U, idx = truncate_covariance(rho_ij.reshape(u**2, u**2), eps)\n",
    "\n",
    "        isometries = np.append(isometries, U[:,:,np.newaxis], axis=2)\n",
    "        indices = np.append(indices, idx)\n",
    "\n",
    "    # get a uniform trancation index for ALL isometries (see Eq. 19)\n",
    "    D = np.min(indices)\n",
    "    # trancating\n",
    "    isometries = isometries[:,D:,:].reshape(u, u, -1, v//2)                   \n",
    "    return isometries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def project(a, iso: np.ndarray, *other: Iterable[np.ndarray]) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    A projector of input tesnor 'a' onto the isometries.\n",
    "    The tensor is first split into 2 parts corresponding\n",
    "    to two input legs of the isoemtry tensor (see picture\n",
    "    below for details).\n",
    "           out      \n",
    "            | \n",
    "           iso  \n",
    "           / \\ \n",
    "    a -> a1   a2\n",
    "\n",
    "    Input:\n",
    "    ------\n",
    "    a:      Tesnor to be projected.\n",
    "    iso:    Tensor with isometries to be projected on.\n",
    "    other:  A tail of the iterable containing isometries. \n",
    "\n",
    "    Output:\n",
    "    -------\n",
    "    A result of the projection.\n",
    "    \"\"\"\n",
    "    # split the array in two parts (correspond to two legs of the input)\n",
    "    a1, a2 = np.split(a, 2, axis=1)\n",
    "    # projection of a onto isometries\n",
    "    out = np.einsum('ilk,jlk,ijml->mlk', a1, a2, iso)\n",
    "    if other:\n",
    "        return project(out, *other)\n",
    "    else:\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tree(a: np.ndarray, eps: Optional[float]=1e-3) -> Iterable[np.ndarray]:\n",
    "    \"\"\"\n",
    "    A tree constructor.\n",
    "\n",
    "    Input:\n",
    "    ------\n",
    "    a:      Array with input data to the tree constructor.\n",
    "    eps:    Trancation tolerance.\n",
    "\n",
    "    Output:\n",
    "    -------\n",
    "    An iterator spitting the isometries for each tree layer.\n",
    "    \"\"\"\n",
    "    # getting the shape of the input tensor\n",
    "    u,v,w = a.shape\n",
    "\n",
    "    assert is_power_of_two(v), 'The number of features must be a power of 2'\n",
    "\n",
    "    # process until stopping criterium\n",
    "    if v > 2:\n",
    "        isometries = go(a, eps=eps)\n",
    "        yield isometries\n",
    "        # creating the input for the next step\n",
    "        a_new = project(a, isometries)\n",
    "        yield from build_tree(a_new, eps=eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_iterator = build_tree(phi_train, eps=7e-2)\n",
    "# reuse the expensive iterator\n",
    "tree_train, tree_test = itertools.tee(tree_iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All data after coarse graining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = data['train']['labels']\n",
    "test_labels = data['test']['labels']\n",
    "\n",
    "train_data = project(phi_train, *tree_train)\n",
    "test_data = project(phi_test, *tree_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11, 2, 60000), (11, 2, 10000))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape, test_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below I want to compare my implementation of CGD to Sklearn Logistic model. Start with Logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "i,j,n = train_data.shape\n",
    "k,l,m = test_data.shape\n",
    "\n",
    "assert i==k and j==l, 'Data shapes mismatch'\n",
    "\n",
    "X_train = train_data.reshape(i*j,n).T\n",
    "X_test = test_data.reshape(k*l,m).T\n",
    "\n",
    "y_train = np.argwhere(train_labels==.99)[:,1]  # need to convert it back as Sklearn require raw labels\n",
    "y_test = np.argwhere(test_labels==.99)[:,1]    # same here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 22)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(multi_class='ovr', solver='newton-cg')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(multi_class='ovr', solver='newton-cg')  # the CGD classifier is also OvA\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for classifier LogisticRegression(multi_class='ovr', solver='newton-cg'):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.66      0.62       980\n",
      "           1       0.39      0.95      0.56      1135\n",
      "           2       0.63      0.40      0.49      1032\n",
      "           3       0.46      0.43      0.44      1010\n",
      "           4       0.51      0.44      0.47       982\n",
      "           5       0.43      0.06      0.11       892\n",
      "           6       0.58      0.51      0.54       958\n",
      "           7       0.43      0.62      0.51      1028\n",
      "           8       0.55      0.37      0.44       974\n",
      "           9       0.59      0.35      0.44      1009\n",
      "\n",
      "    accuracy                           0.49     10000\n",
      "   macro avg       0.51      0.48      0.46     10000\n",
      "weighted avg       0.51      0.49      0.47     10000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "print(f\"Classification report for classifier {model}:\\n\\n\"\n",
    "      f\"{metrics.classification_report(y_test, y_pred)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification confusion matrix:\n",
      "\n",
      "[[ 645   64   27   45   18   31   34  100   15    1]\n",
      " [   2 1079    9   14    0    1    2    2   23    3]\n",
      " [  66  115  413   82   42    7  142   69   85   11]\n",
      " [  42  201   26  432   27   21   23  166   41   31]\n",
      " [  27  208   10   42  430    2   43   78   26  116]\n",
      " [ 130  321   17  168   33   56   26   83   45   13]\n",
      " [ 103   66   50   59  107    5  485   48   27    8]\n",
      " [  22  243   19   10   32    1   32  635    5   29]\n",
      " [  55  242   77   69   16    4   19  101  356   35]\n",
      " [   9  212    8   16  144    1   37  200   28  354]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'Classification confusion matrix:\\n\\n'\n",
    "      f'{metrics.confusion_matrix(y_test, y_pred)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot normalized confusion matrix\n",
    "# fig, ax = plt.subplots(figsize=(12, 12))\n",
    "# disp = metrics.plot_confusion_matrix(\n",
    "#     model, X_test, y_test, \n",
    "#     display_labels=np.arange(10),\n",
    "#     cmap=plt.cm.Blues, \n",
    "#     ax=ax,\n",
    "#     normalize='true')\n",
    "# disp.ax_.set_title(f'Accuracy (Tree TN Compression): {metrics.accuracy_score(y_test, y_pred)}')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training on the original dataset for reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below I want to see how much 'information' is lost after the coarse graining. For this, I train the same logistic regression classifier as above on the full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_images\n",
    "X_test = test_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 64)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(multi_class='ovr', solver='newton-cg')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_orig = LogisticRegression(multi_class='ovr', solver='newton-cg')  # same again, CGD is OvA and I want direct comparison\n",
    "model_orig.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for classifier LogisticRegression(multi_class='ovr', solver='newton-cg'):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93       980\n",
      "           1       0.86      0.94      0.89      1135\n",
      "           2       0.88      0.81      0.84      1032\n",
      "           3       0.80      0.79      0.79      1010\n",
      "           4       0.79      0.79      0.79       982\n",
      "           5       0.75      0.69      0.72       892\n",
      "           6       0.84      0.88      0.86       958\n",
      "           7       0.81      0.84      0.82      1028\n",
      "           8       0.75      0.76      0.75       974\n",
      "           9       0.76      0.71      0.73      1009\n",
      "\n",
      "    accuracy                           0.82     10000\n",
      "   macro avg       0.81      0.81      0.81     10000\n",
      "weighted avg       0.82      0.82      0.82     10000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_orig = model_orig.predict(X_test)\n",
    "print(f\"Classification report for classifier {model}:\\n\\n\"\n",
    "      f\"{metrics.classification_report(y_test, y_pred_orig)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification confusion matrix:\n",
      "\n",
      "[[ 918    1    5    4    0   26   15    3    6    2]\n",
      " [   0 1062    7    6    2   15    7    0   36    0]\n",
      " [  15   34  831   31   19    7   21   12   51   11]\n",
      " [   8   27   30  798    7   62    5   25   27   21]\n",
      " [   4   18    8    4  777   11   29   20   28   83]\n",
      " [  14   12   11   81   25  619   43   10   48   29]\n",
      " [  12    7   14    6   22   29  847    4   14    3]\n",
      " [   4   37   23    5   22    4    2  860    5   66]\n",
      " [  14   27   15   56   19   40   24   24  738   17]\n",
      " [  10   17    4   12   96   13   10  100   28  719]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'Classification confusion matrix:\\n\\n'\n",
    "      f'{metrics.confusion_matrix(y_test, y_pred_orig)}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My conjugate gradient method implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to follow the paper as close as possible (and also learn something along the line). So, I have decided to implement a custom conjugate gradient descent algorithm that the paper is using as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conjugate_gradient(A, b, tol=1e-6):\n",
    "    x = np.ones_like(b)\n",
    "    r = A @ x - b\n",
    "    d = -r\n",
    "    while True:\n",
    "        r2 = r @ r\n",
    "        if np.sqrt(r2) < tol:\n",
    "            break\n",
    "        Ad = A @ d\n",
    "        alpha = r2 / (d @ Ad)\n",
    "        x = x + alpha * d\n",
    "        r = r + alpha * Ad\n",
    "        beta = r @ r / r2\n",
    "        d = -r + beta * d\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing it on a randomly generated dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 701 ms, sys: 42 ms, total: 743 ms\n",
      "Wall time: 92.9 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 1000\n",
    "\n",
    "np.random.seed(0)\n",
    "A = np.random.normal(size=(n,n))\n",
    "A = A.T @ A\n",
    "\n",
    "# below are the requirements of the CGD algorithm.\n",
    "assert ispsd(A), 'The matrix is not PSD'\n",
    "assert ishermitian, 'The matrix is not Hermitian'    \n",
    "\n",
    "b = np.random.rand(n)\n",
    "%time x = conjugate_gradient(A, b)\n",
    "np.allclose(A @ x, b, atol=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a classifier for each digit separately using CGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "i,j,n = train_data.shape\n",
    "k,l,m = test_data.shape\n",
    "\n",
    "assert i==k and j==l, 'Data shapes mismatch'\n",
    "\n",
    "X_train = train_data.reshape(i*j,n).T\n",
    "X_test = test_data.reshape(k*l,m).T\n",
    "\n",
    "y_train = np.argwhere(train_labels==.99)[:,1]\n",
    "y_test = np.argwhere(test_labels==.99)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clf_build(X, y):\n",
    "    \"\"\"\n",
    "    Train a OvA classifier.\n",
    "    \"\"\"\n",
    "    # getting the shape\n",
    "    m,n = X.shape\n",
    "\n",
    "    # assumed number of digits in the dataset\n",
    "    n_digits = 10\n",
    "    \n",
    "    # storing weights\n",
    "    W = np.zeros(shape=(n_digits,n+1), dtype=np.double)\n",
    "    \n",
    "    # adding bias term\n",
    "    X_ = np.ones(shape=(m,n+1), dtype=np.double)\n",
    "    X_[:,1:] = X\n",
    "\n",
    "    # optimize the weights for each digit\n",
    "    for digit in np.arange(n_digits):\n",
    "        y_ = np.where(y != digit, 0.01, 0.99)\n",
    "        # train cgd with square loss\n",
    "        Z = X_.T @ X_\n",
    "        q = X_.T @ y_\n",
    "        W[digit,:] = conjugate_gradient(Z,q)\n",
    "    # returns a set of parameters n_classes x n_features\n",
    "    return W\n",
    "\n",
    "def clf_predict(W, X):\n",
    "    # resizing the arrray if one sample provided\n",
    "    if X.ndim == 1:\n",
    "        X = X[np.newaxis,:]\n",
    "    # getting the shape\n",
    "    m,n = X.shape\n",
    "    # assumed number of digits in the dataset\n",
    "    n_digits = 10\n",
    "    # adding bias term\n",
    "    X_ = np.ones(shape=(m,n+1), dtype=np.double)\n",
    "    X_[:,1:] = X\n",
    "    # stores predictions\n",
    "    y_pred = np.zeros(shape=(m, n_digits), dtype=np.double)\n",
    "    for digit in np.arange(n_digits):\n",
    "        y_pred[:,digit] = X_ @ W[digit,:]\n",
    "    return np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = clf_build(X_train, y_train)\n",
    "y_pred = clf_predict(W, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now also check a single sample..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for classifier LogisticRegression(multi_class='ovr', solver='newton-cg'):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.70      0.63       980\n",
      "           1       0.40      0.97      0.56      1135\n",
      "           2       0.67      0.42      0.51      1032\n",
      "           3       0.48      0.46      0.47      1010\n",
      "           4       0.47      0.61      0.53       982\n",
      "           5       0.51      0.04      0.08       892\n",
      "           6       0.53      0.51      0.52       958\n",
      "           7       0.45      0.54      0.49      1028\n",
      "           8       0.57      0.37      0.45       974\n",
      "           9       0.64      0.20      0.30      1009\n",
      "\n",
      "    accuracy                           0.49     10000\n",
      "   macro avg       0.53      0.48      0.46     10000\n",
      "weighted avg       0.53      0.49      0.46     10000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'Classification report for classifier {model}:\\n\\n'\n",
    "      f'{metrics.classification_report(y_test, y_pred)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification confusion matrix:\n",
      "\n",
      "[[ 683   55   26   26   64   15   26   72    6    7]\n",
      " [   2 1104    3    5    0    0    3    1   16    1]\n",
      " [  66  135  430   95   64    8  112   54   62    6]\n",
      " [  44  179   24  468   31   10   31  167   42   14]\n",
      " [  31  158   11   48  595    0   50   34   13   42]\n",
      " [ 138  266   14  155  100   38   27   89   55   10]\n",
      " [ 116   80   48   67   99    1  486   33   21    7]\n",
      " [  30  293   19   19   43    0   61  552    3    8]\n",
      " [  53  275   63   68   12    2   29   91  365   16]\n",
      " [  12  247    4   28  253    0   84  131   52  198]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'Classification confusion matrix:\\n\\n'\n",
    "      f'{metrics.confusion_matrix(y_test, y_pred)}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sandbox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brute force method (easy to understand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "phi_rand = np.random.rand(3, 196, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "\n",
    "def exec_time(tic, toc):\n",
    "   diff_time = toc - tic\n",
    "   ms = diff_time\n",
    "   m, s = divmod(diff_time, 60)\n",
    "   h, m = divmod(m, 60)\n",
    "   s,m,h = int(round(s, 0)), int(round(m, 0)), int(round(h, 0))\n",
    "   print('Execution Time: ' + f'{h:02d}:{m:02d}:{s:02d}:{ms:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution Time: 00:00:00:0.1829\n"
     ]
    }
   ],
   "source": [
    "l,r = 8,9\n",
    "u,v,w = phi_rand.shape\n",
    "\n",
    "tic = timer()\n",
    "\n",
    "rho1 = np.zeros([u,u,u,u])\n",
    "for j in range(w):\n",
    "    left = np.einsum('ik,ik', phi_rand[:,:l,j], phi_rand[:,:l,j].conj())\n",
    "    right = np.einsum('ik,ik', phi_rand[:,r+1:,j], phi_rand[:,r+1:,j].conj())\n",
    "\n",
    "    # i   m\n",
    "    # |   |\n",
    "    # +---+\n",
    "    # |   |\n",
    "    # +---+\n",
    "    # |   |\n",
    "    # k   n\n",
    "\n",
    "    for i in range(u):\n",
    "        for k in range(u):\n",
    "            for m in range(u):\n",
    "                for n in range(u):\n",
    "                    rho1[i,k,m,n] += left * right * phi_rand[i,l,j] * phi_rand[m,l,j].conj() * phi_rand[k,r,j] * phi_rand[n,r,j].conj()\n",
    "\n",
    "toc = timer()\n",
    "time1 = toc-tic\n",
    "\n",
    "exec_time(tic,toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Same as above, but using vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution Time: 00:00:00:0.0084\n"
     ]
    }
   ],
   "source": [
    "tic = timer()\n",
    "\n",
    "u,v,w = phi_rand.shape\n",
    "\n",
    "l,r = 8,9\n",
    "\n",
    "# computes all density matrices for each j\n",
    "rho2 = np.einsum('ilj,klj->iklj', phi_rand, phi_rand.conj())\n",
    "# contraction of all parts to the left of the pointer (i.e. l)\n",
    "left = np.einsum('ikj,ikj->j', phi_rand[:,:l,:], phi_rand[:,:l,:].conj())\n",
    "# contraction all parts to the right of the pointer (i.e. r+1)\n",
    "right = np.einsum('ikj,ikj->j', phi_rand[:,r+1:,:], phi_rand[:,r+1:,:].conj())\n",
    "# reduced density matrix for the window\n",
    "rho2 = np.einsum('ikj,mnj->imknj', rho2[:,:,l,:], rho2[:,:,r,:])\n",
    "# scaled by left and right\n",
    "rho2 = np.einsum('...j,...j,...j', rho2, left, right)\n",
    "\n",
    "toc = timer()\n",
    "time2 = toc-tic\n",
    "\n",
    "exec_time(tic,toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking that the results are the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(rho1, rho2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.733568237846562"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time1 / time2"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c2262ef1e1764844cc7dddacc5332fc08dc39a3661d4c909d0d650c194bf9ca7"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
